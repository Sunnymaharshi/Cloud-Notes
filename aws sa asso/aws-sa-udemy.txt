Notes:
	Choosing a Region
		Compliance
			data governance and legal requirements
		Proximity
			to customers, to reduce latency
		Available Services
		Pricing
	Availability Zones
		2 to 6, usually 3 in a region
		1 or more discrete data centers
	User access to AWS
		AWS Management Console - password+MFA
		AWS Command Line Interface -  access keys
			direct access to public APIs of AWS services
		AWS Software Development Kit - for code - access keys
			 language specific APIs - libraries
			 access and manage services programatically
	IAM
		Global Service
		inline-policy attached directly to user
		MFA Devices
			Virtual MFA
				Google Authenticator(only phone)
				Authy (multi-device)
			Universal 2nd factor(U2F) Security Key
				physical device like pendrive
			Harware Key Fob MFA Device
			Harware Key Fob MFA Device for AWS GovCloud(US)
		IAM Roles
			we'll asign permissions top services using IAM roles
		
		IAM Security Tools
			IAM Credentials Report (account-level)
				report that have all your acc users and the status
				of their various credentials.
			IAM Access Advisor (user level)
				shows service permissions granted to a user and when 
				those services last accessed
	
			 
			
			
		
	EC2
		IaaS
		User data
			bootstraping - launching Commands when a machine starts
			only run once at the instance first starts
			runs with root user
		public ip may change on stop and start
		Instance types
			General purpose
			Compute optimized
				Batch process
				high performance computing
			Memory optimized
				process large data sets or big unstructured data
				relational and non relational databases
				cache stores
				In-Memory databases
			Storage optimized
				read-write access to large data sets on local storage
				online transaction processing OLTP
				relational and non-relational databases
				Cache for in-memory databases
				warehousing
			memory vs storage optimized ---???
		Security groups
			firewall on EC2 instance
			only allow rules
			can be attached to multiple instances
			locked down to region / VPC combination
		Pricing
			On-Demand 
				linux/windows - pay per sec, after first minute
				other operating systems - pay per hour
				no upfront pay
			Reserved (1 & 3 years)
				Reserved
					upto 72% discount compared to on-demand
					can buy or sell in marketplace
				Convertable Reserved
					upto 66% discount
			Savings plan (1 & 3 years)
				commit to specific amount of usage
				upto 72% discount
				biling at on-demand pricing
				locked at specific instance family and region
				flexible across
					Instance size
					OS
					Tenancy
			Spot instances
				cheap, can loose any time
				upto 90% discount
				define max-spot-price
				get instance while current-spot-price is < max-spot-price --???
				else you can choose stop or terminate the instance with
				2min grace period 
				Spot Block - won't support after 2022
					block spot instance specific time frame 1-6hrs
					without interruptions
				Spot Request 
					max price 
					desired no of instances
					launch specification
					request type
						one-time
							instances launched only once
						persistent
							always launch instances as long as request is valid
					valid from, valid until
				you can only cancel spot instance requests that are open,active or disabled
				cancelling spot requests doesn't terminate instances
				terminate spot Instances
					first cancel spot request
					then terminate associated spot instances
				Spot Fleet
					set of spot instances + (optional) on-demand instances
					meet target capacity with price constraints
					define launch pools:instance type,OS, AZ
					can have multiple pools, so fleet can choose
					allows us to automatically request spot instances with lowest price
					spot fleet stops launching instances when reaching capacity  or max cost
					Strategies
						lowest price
							chooses pool with lowest price
						diversifies
							distributed across all pools
							great for availability and long workloads
						capacityOptimized 
							pool with optimal capacity for no of instances
			Dedicated Hosts
				book an entire physical server
				you can control instance placement in physical server
				use your existing server-bound software licenses
					per-socket
					per-core
					VM software license
				on-demand or reserved
				Software that have model like BYOL (Bring your own license)
				most expensive
			Dedicated Instances
				No other customers will share your hardware
				instances that run on hardware that's dedicated to you
				may share hardware with other instances in same account
				No control over instance placement
			Capacity Reservations
				Reserve Capacity in specific AZ for any duration
				No biling discounts
				charged even instances are not running

		Elastic IPs
			when you start and stop the EC2, it can change its public IP
			if u need a fixed IP, u need an Elastic IP
			attach to one instance at a time
			u can only have 5 Elastic IPs in ur account (u can ask aws to increase)
		Placement Groups
			control EC2 instance placement strategy
			Strategies
				Cluster
					clusters the instances into low latency group in a Single AZ
					same rack, if rack fails then all instances fail
					low latency
				Spread
					spreads instances across underlying hardware
					all EC2 are on different hardware
					max 7 instances per placement group per AZ
					max availability
					critical applications
				Partition
					partition is rack
					spreads instances across many different partitions within an AZ
					upto 7 partitions per AZ
					can span across multiple AZs in same region
					scales to 100s of EC2 instances per group
					EC2 instances get access to partition information as metadata
					Hadoop, Cassandra, kafka
			
		Elastic Network Interfaces (ENI)
			logical component in a VPC that represents a virtual network card
			Bound to specific AZ
			have private and public IPs, mac address, can have elastic IPs and security groups.
			can create ENI independently and attach them on EC2 instances over network failover.
		EC2 Hibernate
			in-memory (RAM) is preserved
			instance boot is faster
			must be EBS, encrypted, not instance store and large
			hibernate not more than 60 days 

		Elastic Block Store(EBS) Volume
			network drive
			can attach while EC2 run
			1 EBS can only mounted to 1 EC2, "multi-attach" feature for some EBS
			Bound to specific AZ, to move across AZ u need to snapshot it
			dettach and attach quickly
			delete on termination is selected by default only to root volume
			Types
				general purpose SSD
					gp2,gp3(SSD)					
					cost effective, low latency					
				Provisioned IOPS (PIOPS) SSD
					io1,io2(SSD)
					high-perf SSD
					mission critical, low latency or high-perf throughput
					database workloads
					supports "multi attach"
					max IOPS 64000 for nitro EC2, 32000 for other
					Multi Attach
						can attach EBS to multiple EC2 in same AZ
						upto 16 EC2 at a time
						must use File system that's cluster aware
				Throughput optimized HDD
					st1(HDD)
					low cost HDD					
					frequently accessed, throughput-intensive workloads
					cannot be boot volume
					max throughput 500MiB/s max IOPS 500
				Cold HDD
					sc1(HDD)
					lowest cost HDD					
					less frequently accessed workloads
					cannot be boot volume
					max throughput 250MiB/s max IOPS 250
			only gp2/gp3 and io1/io2 can be used as boot volumes
			
					
		EBS Snapshots
			backup of EBS at any point of time
			dettach EBS to snapshot it is recommended but not necessary
			can copy snapshots across AZ or region
			Archive tier
				75% cheap
				24-72hrs to restore
			Recycle Bin
				can setup rules to retain deleted snapshots 
				retention can be 1day - 1year
			Fast Snapshot restore
				force full initialization of snapshot 
				to have no latency on first use
		EBS Encryption
			minimal impact on latency
			encrypt unencrypted EBS volume
				create snapshot
				encrypt it using copy
				create new volume from it
				attach it to original instance
				or
				create volume directly from it with encryption
		Amazon Machine Image (AMI)
			customization of EC2 instance
			bound to specific region (can be copied across regions)
			custom AMI has faster bootup with needed configuration and softwares
		EC2 Instance Store
			high-performance hardware disk
			directly attached to instance
			loss storage if stoped
		Elastic File System (EFS)
			network file system that can be mounted on many EC2
			in multi-AZs
			uses security group to control access to EFS
			compatable with "Linux based AMI" (not windows) as it is POSIX file system
			1000s of concurrent NFS clients, 10Gbps+ throughput
			petabyte scale automatically
			Performance mode(set at EFS creation time)
				General purpose(default)
					latency sensitive use cases
					web server, CMS etc
				Max I/O
					higher latency, throughput, highly parallel
					big data, media processing
			Throughput mode
				Bursting
					1TB = 50MiB/s + burst of upto 100MiB/s
					Throughput scales with file system size
				Provisioned
					set ur throughput regardless of storage size
			EFS Storage Classes
				Standard
					for frequently accessed files
				Infrequent access(EFS-IA)
					cost to retrieve files
					lower price to store
			Availability
				Regional(Standard)
					Multi-AZ
				One Zone
					backup enabled by default
					compatible with IA (EFS One Zone-IA)
					over 90% savings
					
			
		Scalability
			Vertical
				increase the size of the instance
			Horizontal
				increase the no of instances
		High Availability
			goal is to survive data center loss
			u run ur application in atleast 2 data centers or AZs
		Elastic Load Balancer
			spread load across multiple instances
			expose single point of access(DNS) to ur application
			handles failures of instances
			regular health checks
			SSL termination(HTTPS) for websites
			Types
				Classic(deprecated, but still available)
					HTTP HTTPS(layer 7),TCP(layer 4),SSL
					deprecated, but still available
				Application
					layer 7 only
					HTTP,HTTPS,websocket
					can route different services in same machine(containers)
					Routing to different target groups
						url path
						hostname in url
						query string, headers
					Target Groups
						EC2 instances
						ECS tasks - HTTP
						Lambda functions 
						IP Addresses - must be private
					application servers don't see clients IP directly
					Connection termination occurs here
					client IP is inserted in header X-Forwarded-For
					Port(X-Forwarded-Port), proto (X-Forwarded-Proto)
				Network (layer 4)
					TCP,TLS(secure TCP),UDP
					1 static IP for AZ, supports Elastic IP
					Target Groups
						EC2 Instances
						IP Addresses - must be private
						Application Load Balancer
					Health checks supports TCP, HTTP and HTTPS
				Gateway (layer 3 - Network layer - IP packets)
					operates at layer 3 (network layer) - IP Protocol
					to inspect all network traffic
					distributes traffic to ur 3rd party Security virtual appliances
					Target Group
						EC2 Instances
						IP Addresses - must be private
					features
						transperent network gateway
							single entry/exit for all traffic
						load balancer
							distributes traffic to ur virtual appliances
					uses GENEVE protocol on port 6081
			quiz
				1.Only Network Load Balancer provides both static DNS name and static IP. 
				Application Load Balancer provides a static DNS name 
				but it does NOT provide a static IP.	
				2.Network Load Balancer provides the highest performance and lowest latency 
				if your application needs it.
				3.Network Load Balancer has one static IP address per AZ 
				you can attach an Elastic IP address to it.
				Application Load Balancers and Classic Load Balancers have a static DNS name.	
			Sticky Sessions (Session Affinity)
				same client is always redirects to same instance behind load balancer
				works for Classic and Application load balancers
				cookie used for stickiness has an expire data you control
				user doesn't lose his session data
				Application-based Cookie
					Custom Cookie
						Generated by target(application)
						can include any custom attributes required by application
						Cookie must be specified for each target group
						Don't use AWSALB, AWSALBAPP, AWSALBTG (reserved for use of ELB)
					Application Cookie
						generated by "load balancer"
						cookie name AWSALBAPP
				Duration-based Cookie
					generated by load balancer
					AWSALB for ALB, AWSELB for CLB
					
			With Cross-Zone load balancing
				each load balancer instance distributes evenly across all
				registered instances in all AZs.
				ELBs considers all registered intances in all AZs, distributes traffic evenly
				used when there is imbalance in no of instances in AZs
			Without Cross-Zone load balancing
				requests distributes in the instances of node of ELB
				ELB considers only it's registered instances, spread traffic amoung them evenly.
			Cross-Zone load balancing
				Application LB
					Always on (can't disable)
					No charges for inter AZ data transfers
				Network LB
					disable by default
					charges applied for inter AZ data transfers if enabled	
				Classic LB
					disable by default
					No charges for inter AZ data transfers if enabled
					
			SSL/TLS
				SSL certificate allows traffic between ur clients and ur load balancer
				to be encrypted in trasit (in-flight encryption)
				SSL - Secure Socket Layer used to encrypt connections
				TLS - Transport Layer Security newer version of SSL
				have expiration date
				you can manage certificates using ACM (AWS Certificate Manager)
				can upload own certificates alternatively
				HTTPS listener
					must specify default certificate
					can all optional list of certs to support multiple domains
					clients use SNI(Server Name Indication) to specify the hostname they reach
					ability to specify security policy to support older versions 
					of SSL/TLS(legacy clients)
				Server Name Indication (SNI)
					solves problem of loading "multiple SSL certs" onto one webserver
					it is newer protocol, requires client to indicate the hostname of
					target server in the initial SSL handshake
					Server will then find the correct SSL cert and return default one
					only works for ALB and NLB(new generation LBs) and Cloud Front
					not work in CLB
				CLB
					supports only one SSL cert
					Must use multiple CLBs for multiple hostnames with multiple SSL certs
				ALB,NLB
					supports multiple listeners for multiple SSL certs
					uses SNI to make it work
			Connection Draining
				Connection Draining for CLB
				Deregistration Delay for ALB,NLB
				time to complete "in-flight requests" while the instance is de-registering or unhealthy
				ELB stops sending new requests while instance is de-registering
				1-3600sec(default 300)
				can disable by setting it to 0
		Auto Scaling Group
			create and delete servers very quickly
			automatically register new instances to load balancer
			re-create new instance if previous one is terminated or unhealthy
			free, u only pay for underlying EC2 instances
			u set min,desired and max capacity u want
			Launch Template
				AMI + instance type
				EC2 user data
				EBS volumes
				Security Groups
				SSH key pair
				IAM roles for EC2
				Network + subnets
				Load balancer information etc
			Min,Max,Initial Capacity
			can scale ASG based on CloudWatch alarms 
			alarm monitors a metric like CPU etc
			Dynamic Scaling Policies
				Target Tracking Scaling
					most simple and easy to setup
					example: i want average ASG CPU to stay around 40%
				Simple/Step Scaling
					CloudWatch alarm is triggered(CPU>70%), the add 2 instances
				Scheduled Actions
					Anticipate scaling based on known usage patterns
					example: increase min capacity to 10 at 5pm on Fridays
			Predictive Scaling
				continuously forecast load and schedule scaling ahead
			Good Metrics to Scale on
				CPU utilization
				RequestCountPerTarget
				Average Network In/Out
				Any Custom metric
			Scaling Cooldowns
				after a scaling activity, u are in cooldown period (default 300sec)
				during cooldown period ASG will not launch or terminate additional instances
					
	Amazon RDS
		Relational Database Service
		Managed DB service which use SQL as query language
		Database Engines
			Postgres
			MySQL
			MariaDB
			Oracle
			Microsoft SQL Server
			Aurora(AWS Proprietary database)
		Automated provisioning, OS patching
		Continous backup and restore to specific timestamp(Point in time Recovery)
		Monitoring Dashboards
		Read Replicas for improved read performance
		Multi-AZ setup for Disaster Recovery
		Maintenance windows for upgrades
		Scaling(virtical and horizontal)
		Storage backed by EBS (gp2 or io1)
		Can't SSH into instances
		Storage Auto Scaling 
			u have to set max storage threshold
		Automatically modify storage if
			free storage is less than 10% of allocated storage
			low-storage lasts at least 5min
			6hrs passed since last modification
		Read Replicas
			upto 5 read replicas
			within AZ or cross AZ or cross Region
			Replication is ASYNC, reads are eventually consistent
			can be promoted to their own DB
			used for only SELECT kind of statements
			applications must update connection string to leverage read replicas
			Network Cost(replication fee)
				u don't pay for RDS Read Replicas within same region
				u have to pay for Cross Region Read Replicas
		RDS Multi-AZ (Disaster Recovery)
			SYNC replication
			one DNS name, automatic app failover to standby
			Increase Availability
			not used for scaling
		Read Replicas can be setup as Multi-AZ for Disaster Recovery
		RDS from Single AZ to Multi AZ
			Zero downtime operation
			click on 'Modify', then enable Multi-AZ
		RDS Custom
			Full admin access to underlying OS and Database, customization
			Supports Managed Oracle and Microsoft SQL Server		
			Configure Settings
			Install patches
			Enable native features
			SSH or SSM Session Manager to underlying EC2 instance		
			De-activate Automation Mode before customization
			better to take DB snapshot before		
		Aurora
			proprietary technology from AWS (not opensourced)
			Supports Postgres and Mysql
			Cloud optimized 5x over MySql on RDS, 3x over Postgres on RDS
			storage automatically grows in increments of 10GB upto 128GB
			15 Replicas while MySQL has 5, replication process is faster
			Failover is instantaneous. it's HA native
			costs 20% more than RDS but more efficient
			High Availability and Read Scaling
				6 copies of data across 3 AZs
					4 out of 6 needed for writes
					3 out of 6 need for reads
					Self healing with peer-to-peer replication
				One Aurora instance takes writes (master)
				Automated failover for master in less than 30sec
				Master + upto 15 read replicas
				Support Cross region replication
			Aurora DB Cluster
				Writer Endpoint
					pointing to master
				Reader Endpoint
					Connection load balancing - automatically connects to one of read replicas
					As we can set autoscaling to read replicas
				Cutom Endpoints
					define subset of Aurora instances as Custom Endpoints
			Features
				Automatic failover
				Backup and recovery
				Isolation and security
				Push-button scaling
				Automated patching with Zero downtime
				Advanced Monitoring
				Routine Maintenance
				Backtrack
					restore data at any point of time without using backups			
			Aurora Serverless
				automated database instantiation and autoscaling based on actual usage
				good for infrequent or unpredictable workloads
				No capacity planing needed
				pay per sec, more cost effective
			Aurora Multi-Master
				immediate failover to write node(HA)
				every node does Read/Wirte, can promote read replica as new master
			Global Aurora 
				Cross region read replicas
					disaster recovery
					Simple
				Aurora Global Database (reccomended)
					1 primary region
					upto 5 secondary (read-only) regions 
					cross region replication takes less than 1sec
					upto 16 read replicas per secondary region
					Promoting another region has RTO less than 1min
			Aurora Machine Learning
				add ML-based predictions to ur application via SQL
				Simple,optimized and secure integration between Aurora and AWS ML services
				Services
					Sage Maker (use with any ML model)
					Comprehend (for sentiment analysis)
				No need of ML experience		
		RDS Backups
			Automated Backups
				Daily full backup of db (during maintenance window)
				transaction logs backed up every 5min
				restore to any point in time (oldest backup to 5min ago)
				1-35 days retention, 0 to disable automated backups
			Manual DB Snapshots
				Manually triggered by user 
				retention is as long as u want
			In stopped RDS, u still pay for storage
			If u plan to stop RDS for long time, take snapshot and delete RDS
		Aurora Backups
			Automated Backups
				1-35 days retention (can't be disabled)
				point in recovery in that timeframe
			Manual DB Snapshots
				Manually triggered by user 
				retention is as long as u want	
		RDS & Aurora restore
			Restoring RDS/Aurora backup or snapshot creates a new database
			Restoring Mysql RDS from S3
				create backup of on-premise db
				store it in S3
				restore it onto a new a new RDS instance running Mysql
			Restoring Mysql Aurora cluster from S3
				create backup of on-premise db using Percona Xtra backup
				store it in S3
				restore it onto a new a new Aurora cluster running Mysql
		Aurora Database Cloning
			create new aurora db cluster from an existing one
			faster than snapshot and restore
			new cluster uses same cluster volume and data as original
			but will change when data updates are made
			useful when creating staging db from production db without impacting prod db
		RDS & Aurora Security
			at-rest encryption
				database master and replicas encryption using AWS KMS - must be defined at launch time
				if master is not encrypted, the read replicas cannot be encrypted
				to encrypt an un-encrypted database, go through a DB snapshot & restore as encrypted
			In-flight encryption
				TLS-ready by default, use AWSTLS root certificates client side
			IAM Authentication
				IAM roles to connect to database (instead of usr/password)
			Security groups
				control network access to RDS/Aurora
			No SSH access
				except on RDS custom
			Audit logs can be enabled and sent to CloudWatch logs for longer retention
		Amazon RDS Proxy
			fully managed database proxy for RDS 
			allow apps to pool and share db connections
			Improve database efficiency by reducing stress on CPU and RAM and minimize open connections
			Serverless, autoscaling high availability(multi -AZ)
			Reduced RDS & Aurora failover time by 66%
			Supports RDS(MySQL,PostgresSQL, MariaDB, MS SQL server) and Aurora(MySQL,PostgresSQL)
			Enforce IAM Authentication for DB and securely store credentials in AWS Secrets Manager
			RDS Proxy is never publically accessible (must be accessed from VPC)
		Amazon ElasticCache
			Managed Redis or Memcached
			in-memory databases with high perf, low latency
			helps reduce load on database for read intensive workloads
			helps make your application stateless
			Using ElasticCache involve heavy application changes
			Redis 
				Multi-AZ with auto-failover
				read-replicas to scale reads and have high-availability
				Data Durability using AOF persistence
				Backup and restore features
				Supports sets and sorted sets
			Memcached
				Multi node for partitioning of data (sharding)
				No HA (replication)
				Non persistent
				No Backup & restore
				Multi threaded architecture
			Security 
				IAM Authentication for Redis
				IAM Policies are only for AWS API-level security
				Redis Auth
					you can set password/token when you create a redis cluster
					SSL in-flight encryption
				Memcached
					SASL-based Authentication(Advanced)
			lazy loading
				all the read data is cached, data can become 
				stale(data that hasn't been updated at the frequency interval required for its productive use) in cache 
			Write Through 
				Add or updates data in cache when written to DB (no stale)
			Session store
				store temporary data in a cache(TTL features)
			Redis Use case
				Gaming leaderboards are computationally complex
				Redis Sorted sets
			Quiz
				You have set up read replicas on your RDS database, but users are complaining 
				that upon updating their social media posts, they do not see their updated posts right away. 
				What is a possible cause for this?
					Read Replicas have Asynchronous Replication, therefore it's likely your users will 
					only read Eventual Consistency
				How can you enhance the security of your ElastiCache Redis Cluster by allowing users to access your 
				ElastiCache Redis Cluster using their IAM Identities (e.g., Users, Roles)?
					IAM Authentication
				You would like to create a disaster recovery strategy for your RDS PostgreSQL database 
				so that in case of a regional outage, a database can be quickly made available 
				for Read and Write workload in another region. The DR database must be highly available.
					Create a Read Replica in a different region and enable multi-AZ on the main database
				RDS database, you can have up to ............ Read Replicas.
					15
				How many Aurora Read Replicas can you have in a single Aurora DB Cluster?
					15
				You need to store long-term backups for your Aurora database for disaster recovery and audit purposes.
					Perform On Demand Backups
				Your development team would like to perform a suite of read and write tests against your production 
				Aurora database because they need access to production data as soon as possible.
					Aurora Cloning

	Route 53
		Domain registrar
		fully managed and Authoritative(customer can update DNS records) DNS 
		Only AWS service with SLA 100% availability
		53 is reference to traditional DNS port
		DNS records 
			A,AAAA,CNAME,NS...
		Zone file
			contains DNS records
		Name server
			resolves DNS queries 
		Top level Domain(TLD)
			.com,.us,.in,.gov...
		Second level Domain(SLD)
			amazon.com,google.com...
		Record contains
			domain/sub domain name
				example.com
			Record type
				A, AAAA
			Value
				12.23.56.78
			Routing policy
				how route 53 responds to queries
			TTL
				amount of time the record cached at DNS resolvers
		Route 53 supports following record types
			A
				maps hostname to IPv4
			AAAA
				maps hostname to IPv6
			CNAME
				maps a hostname to another hostname
				target domain must have A or AAAA record
				can't create a CNAME record for top node of DNS namespace(Zone apex)
				can't create for example.com but can create for www.example.com
			NS
				Name servers for hosted Zone
				Hosted Zone
					A container for records that define how to route traffic to a domain and it's subdomains
					public hosted zones
						contains records that specify how to route traffic on the internet (public domain names)
					private hosted zones
						contains records that specify how to route traffic within one or more VPCs (private domain names)	
		Records TTL	(Time to Live)
			Except for alias records, TTL is mandatory for each record
		CNAME 
			points a hostname to any other hostname 
			only for not root domain (something.mydomain.com)
		Alias
			specific to route 53
			points a hostname to an AWS Resource
			works for both root(mydomain.com)(Zone Apex) and non root domains
			free
			Native health check
			extension to DNS functionality
			automatically recognizes changes in resource's IPs
			can't set TTL 
			can't set Alias for an EC2 DNS name
		Routing Policies
			Defines how route 53 responds to DNS queries
			health checks
				only for public resources
				Automated DNS failover
				checks
					Endpoint
						app
						server
						AWS resource
					health checks
						Calculated health checks
							combine result of multiple health checks with OR, AND or NOT
							upto 256 child health checks
					CloudWatch alarms
						alarms on RDS
						custom metrics 
						for private resources
							create CloudWatch metric
							associate with CloudWatch alarm
							create health check that chechks the alarm
				Configure firewall to allow Route 53 health checks
			Simple
				single value
				multiple value
				can't be associated with health checks
			Weighted
				% of requests that go to specific resource
				can have health checks
				if all the records have weight 0, all records will be returned equally			
			Latency based
				redirect to resource that has least latency close to us
				have the health checks
			Failover
				primary resource and secondary resource
				mandatory health check
			Geolocation
				specify location by continent, Country or by State
				Default record if no match on location
			Geoproximity
				based on geographic location of users and resources
				ability to shift more traffic to resources based on the defined bias
				to change the size of geographic region, specify bias values 
					to expand (1 to 99)
						more traffic to resource
					to shrink (-1 to -99)
						less traffic to resource
				must use route 53 traffic flow to use this feature
			IP based
				based on clients IP 
				you provide list of client's CIDRs and corresponding endpoints/locations
				user IPs to endpoint mappings
			Multi-Value
				use when routing traffic to multiple resources
				return multiple values/resources
				can have health checks
				upto 8 healthy resources are returned for each query
				not a substitute for Elastic Load Balancer
		If you buy a domain in 3rd party registrar, you can still use Route 53 as the DNS Service provider
		Domain Registrar!=DNS Service
		Quiz 
			You have purchased a domain on GoDaddy and would like to 
			use Route 53 as the DNS Service Provider. What should you do to make this work? 
				Create a Public Hosted Zone and update the 3rd party Registrar NS records 
	
	Solutions Architecture
		Cost Management
			reserved instances
		Instantiating applications quickly
			EC2
				Golden AMI
					Install app and all dependencies beforehand 
					lauch EC2 from golden AMI
				Bootstrap using User Data 
					User Data scripts
				Hybrid
					mix of Golden AMI & User Data (Elastic Beanstalk)
			RDS 
				Restore from snapshots
			EBS Volumes 
				Restore from snapshots
		Elastic Beanstalk(PaaS)
			Developer centric view of deploying an application on AWS
			Managed Service
				Automatically handles capacity, load balancing, scaling, health Monitoring, instance configuration
				just app code is responsible for the configuration
			Free but need to pay for underlying resources
			Application
				collection of Beanstalk components
			Application version 
				an iteration of application code
			Environment
				collection of AWS resources running an app version 
				Tiers
					webserver Environment & worker Environment tier 
				can create multiple environments
			platforms
				Go, Jave SE, Java with Tomcat, .NET Core on Linux 
				.NET on windows server, Node.js, PHP, Python
				Ruby, Packer Builder, Single Container Docker
				Multi-container Docker, Preconfigured Docker
			custom platform
			Web Environment
				Elastic LoadBalancer
				autoscaling group
			Worker Environment
				SQS Queue
				autoscaling group
				scale based on no of SQS messages
				can push messages to SQS queue from another WebServer Tier
			Deployment Modes
				Single Instance 
					dev
					Elastic IP,EC2,RDS master
				High Availability with load balancer
					ALB, autoscaling group
					RDS Master and RDS Standby
		Quiz	
			Which of the following will NOT help us while designing a STATELESS application tier?
				Store session data on EBS volumes
			You're deploying your application to an Elastic Beanstalk environment 
			but you notice that the deployment process is painfully slow. 
			After reviewing the logs, you found that your dependencies are resolved 
			on each EC2 instance each time you deploy. How can you speed up the deployment process with minimal impact?
				Create a Golden AMI that contains the dependencies and use that image to launch the EC2 instances
	
	Amazon S3
		Buckets 
			globally unique Name
			Regional level
			Naming
				No uppercase, No underscore
				3-63 char long
				Not an IP
				Must startwith lowercase no or number 
		Objects
			Key
				full path
				s3://my-bucket/note.txt
				prefix + object name
			values are content of object
			max size 5TB
			> 5TB must use multi-part upload
			Metadata
				list of text key/value pairs
			Tags
			version ID (if versioning is enabled)
		
		User-based
			IAM Policies
				which API calls should be allowed for specific user from IAM
		Resource based
			Bucket Policies
				bucket wide rules from S3 console 
				allows cross account
			Object Access Control list (ACL)
				finer grain (can be disabled)
			Object Access Control list (ACL)
				less common (can be disabled)
		Encryption
			encrypt objects using encryption keys
		Bucket Policies
			JSON based
				resources 
					Buckets & Objects
				Effect
					Allow/Deny 
				Actions 
					Set of API 
			Usecases
				Grant public access to bucket 
				Force objects to be encrypted at upload 
				Grant access to another account (Cross account)
		Bucket Settings (Block all public access)
			To Prevent company data leaks 
			If bucket should never be public, leave these on 
			Even if we set bucket policy for public it won't be public 
			Can be set at account level 
		Can Host Static websites 
		Versioning
			enabled at bucket level 
			any file that is not versioned prior to enabling versioning will have version "null"
			Suspending versioning will not delete previous versions 
		Replication
			Must enable versioning in source and destination
			cross region replication (CRR)
				compliance, lower latency access, replication across accounts
			same region replication (SRR)
				log aggregation, live replication between prod and test accounts 
			buckets can be in different AWS accounts 
			Copy is Asynchronous
			After enable only new objects are replicated 
			can replicate existing objects using batch replication
				replicate existing and failed replication objects
			For Delete 
				can replicate delete markers from source to target (optional)
				Deletions with a version ID are not replicated (to avoid malicious deletes)
			no chaining 
				bucket 1 to 2, bucket 2 to 3, does not 1 to 3
		Storage Classes
			General purpose
				99.99% availability
				used for frequently accessed data
				low latency high throughput
				sustain 2 concurrent facility failure 
			Infrequent Access
				less frequently accessed but requires rapid access 
				lower cost than General purpose
				Standard-Infrequent Access
					99.9% availability
				One Zone-Infrequent Access
					99.5% availability
			Glacier
				low cost
				archiving/backup
				price for storage + object retrieval cost 	
				Glacier Instant retrieval
					milisec retrieval
					data accessed once for quarter 
					min storage duration 90 days
				Glacier Flexible retrieval
					min storage duration 90 days
					Expedited 
						1 to 5min 
					Standard
						3 to 5hrs
					Bulk 
						5 to 12hrs 
						free
				Glacier Deep Archive
					long term 
					min storage duration 180 days
					Standard
						12hrs
					Bulk
						48hrs
			Intelligent-Tiering
				small monthly Monitoring and auto-tiering fee
				no retrieval charges
				frequent access tier(automatic)
					default tier 
				Infrequent access tier(automatic)
					not accessed for 30 days 
				Archive Instant Access Tier(automatic)
					not accessed for 90 days 
				Archive Access Tier(optional)
					configurable 90 to 700+ days
				Deep Archive Access Tier(optional)
					configurable 180 to 700+ days
		Quiz 
			Multi-Part Upload is recommended as soon as the file is over 100 MB.
		Moving between classes 
			can only move to any of classes below it
			Standard
			Standard IA 
			Intelligent Tiering
			One Zone IA 
			Glacier Instant retrieval
			Glacier Flexible retrieval
			Glacier Deep Archive
			Life cycle rules 
				Transition Actions 
					Move to Glacier after 6 months
				expiration actions 
					delete after some time 
					can delete older versions of files (if versioning is enabled)
					can delete incomplete Multi-Part uploads
				Rules can be created for a certain prefix, object Tags
			Storage Class Analysis 
				recommendation for standard and standard IA 
				not for One Zone and Glacier 
				report is updated Daily
				24 to 48 to start seeing data analysis
		Requester Pays
			requester instead of bucket owner pays cost of request and data download from bucket
			networking costs 
			helpful when you want to share large datasets with other accounts
			requester must be authenticated in AWS(can't be anonymous)
		S3 Event Notifications 
			Object created, removed, restore, Replication
			Object name filtering possible (*.jpg)
			Use case
				generate thumbnails of images uploaded to S3 
			can create as many S3 Events as desired
			typically deliver events in seconds but can sometimes take a minute or longer 
			To send to any of SNS,SQS and labmda we need to attach resource (Access) policy
			EventBridge
				all events will end up here 
				Advanced filtering options with JSON rules
				multiple destinations
				event bridge capability
					Archive
					replay 
					reliable delivery
		S3 Performance
			Multi-Part Upload
				recommended for > 100MB 
				must for files > 5GB
				can help paralize uploads 
			S3 Transfer Acceleration
				Increase transfer speed by transfering file to an AWS Edge location 
				which will forward the data to S3 bucket in the target region 
				compatible with multi-part upload
			S3 Byte-Range Fetches 
				paralize GETs by requesting specific byte ranges 
				can request parallel
				Better resilience in case of failure 
				can speed up downloads
				can be used to retrieve only partial data 
			S3 Select & Glacier Select
				serverside filtering in file(object)
				retrieve less data using SQL 
				filter by rows and columns
				less network transfer, less CPU cost client side 
				use case
					Get filtered dataset from CSV 
			S3 Batch Operations 
				perform bulk operations on existing S3 objects with a single request 
				example
					Modify object metadata & properties 
					Copy objects between S3 buckets
					encrypt unencrypted objects 
					Modify ACLs, Tags
					Restore objects from Glacier
					Invoke lambda function to perform custom action on each object.
				A Job consists of list of objects, action and optional parameters
				manages retries, tracks progress, send completion Notifications, generate reports
				Can use S3 Inventory to get objects list and S3 Select to filter objects
		S3 Security
			Encrypt 
				Server side encryption (SSE)
					Amazon S3 Managed Keys (SSE-S3)
						Enabled by default
						AES-256
						must set header "x-amz-server-side-encryption":"AES256"
					Server side encryption with KMS (SSE-KMS)
						Keys stored in AWS KMS 
						keys handled and managed by KMS 
						user control over key + audit key usage using CloudTrail
						must set header "x-amz-server-side-encryption":"aws:kms"
						KMS 
							when you upload it calls the GenerateDataKey KMS API
							when download it calls the Decrypt KMS API
					Server side encryption with Customer provided Keys (SSE-C)
						when you want to manage your own keys 
						keys managed outside aws 
						aws doesn't store the ecryption key you provide 
						HTTPS must be used 
						Key must be provided in HTTP headers, for every http request 
						only through CLI
					Dual layer server side encryption with KMS (DSSE-KMS)
				Client side encryption 
					Use client libraries such as Amazon S3 Client-Side Encryption Library
					client must encrypt data before sending to aws 
					customer fully manages keys and encryption cycle 
				Encryption in Transit(SSL/TLS)
					HTTPS is recommended
					HTTPS is mandatory for SSE-C 
					Force encryption in transit using Bucket policy

				Default encryption vs Bucket Policies
					SSE-S3 encryption is automatically applied to new objects 
					Optionally u can force encryption using a bucket policy 
						refuse any API call to PUT an object without encryption headers 
					bucket policies always encrypted before "default encryption"
			CORS 
				Cross-Origin Resource sharing 
				Origin =  scheme(protocol) + host(domain) + port 
				Web browser based mechanism to allow requests to other origins while visiting the main origin
				Requests won't be fulfilled unless other origin allows for requests using CORS
				If client makes a cross origin request on S3 bucket, we need to enable the correct CORS headers
				can allow specific origin or all 
			MFA Delete
				force users to generate a code on device(mobile or hardware) before doing
				important operations on S3
				versioning must be enabled to use MFA 
				only bucket owner(root acc) can enable/disable MFA Delete
				required to
					permanently delete object version
					suspend versioning
				not required
					enable versioning 
					list deleted versions 
			Access logs 
				target logging bucket must be in same AWS region
				Do not set your logging bucket to be Monitoring bucket
				it'll create infinite logging loop
			Pre Signed URLs
				can generate using console, cli or sdk
				URL expiration
					console 
						1-720min (12hrs)
					CLI 
						default 3600sec
						max 604800sec ~ 168hrs
				for GET/PUT 
			Glacier Vault lock 
				Adopt WORM(write once and read many)
				create vault lock policy 
				lock the policy
			Object Lock 
				versioning must be enabled
				WORM model 
				block object version deletion for a specific time 
				Retention Mode - Compliance
					Object versions can't be overwritten or deleted by any user, including root user 
					Object retention modes can't be changed and retention periods can't be shortened
				Retention Mode - Governance 
					Most users can't overwrite or delete object version or alter its lock settings 
					Some users have permission to change the retention or delete the object 
				Retention period 
					protect the object for a fixed period, it can be extended 
				Legal Hold 
					protect the object indefinitely, independent from retention period and retention mode 
					can be freely placed and removed using the s3:PutObjectLegalHold permission
			S3 Access Points 
				policy 
				each has it's own DNS 
				manage security at scale (prefix/folder)
			S3 Object Lambda
				Use AWS lambda functions to change object before it is retrieved by caller application
				access through lambda access point 
				use cases 
					redacting PII info 
					converting data format 
					resizing 
	Cloud Front 
		Global Service
		Content Delivery Network(CDN)
		content is cached at edge location
		216 point of presence globally (edge locations)
		DDoS protection 
		Integration with shield 
		AWS Web Application Firewall (WAF)
		Origins 
			S3 bucket
				Enhanced security with CloudFront Origin Access Control(OAC)
				OAC is replacing Origin Access Identity (OAI)
				can be used as ingress (to upload files to S3)
			Custom Origin (HTTP)
				Application load balancer (ALB)
				EC2 Instance
				S3 website (must first enable bucket as static S3 website)
				Any HTTP backend
		files are cached for TTL (maybe a day)
		Great for static content that must be available everywhere
		S3 cross region replication 
			Read only, files are updated in near real-time
			for dynamic content that needs to be available at low latency in few regions 
		Geo Restriction
			Allowlist
				allow users to access content only if they're in one of the countries on list 
			Blocklist 
				to block users from countries in list 
		Price Classes
			can reduce no of edge locations for cost reduction
			Price Class All
			Price Class 200
				most regions but exclude most expensive regions 
			Price Class 100
				only have least expensive regions 
		Cache Invalidation
			can force entire or partial cache refresh 
			can invalidate all files(*) or specific path(/images/*)

	AWS Global Accelerator
		Leverage AWS internal network to route to your app
		2 Anycast IPs are created for app
		Anycast IP send traffic directly to edge locations
		Works with 
			Elastic IP 
			EC2 instance
			ALB
			NLB 
			public or private
		Consistent performance
			Intelligent routing to lowest latency and fast regional failover
			No issue with client cache (because IP doesn't change)
			Internal AWS Network
		health checks 
			Helps your app global(failover in less than 1min)
			disaster recovery
		Security
			only 2 external IP need to be whitelisted 
			DDoS protection (AWS Shield)
		CloudFront vs AWS Global Accelerator
			CloudFront
				Improves performance for both cacheable and dynamic content
				content is served at edge locations 
			Global Accelerator
				imporve performance of wide range of apps over TCP or UDP
				Proxying packets at edge locations to apps running in one or more AWS regions 
				Good fit for non-HTTP use cases 
					gaming(UDP), IoT(MQTT) or Voice over Ip 
				Good for HTTP use cases that require static IPs
	
	AWS Storage Extras 
		AWS Snow Family 
			highly-secure portable devices to collect and process data at edge
			migrate data into and out of AWS 
			offline devices to perform data migrations
			if it takes more than 1 week to transfer over the network, use Snow Family 
			Data migration
				Snowcone
				Snowball edge
				Snowmobile 
			Edge computing 
				Snowcone
				Snowball Edge 
			Snowball Edge 
				move TBs or PBs of data in or out of AWS
				pay per data transfer job 
				provide block storage and S3 compatible object storage
				Snowball Edge Storage Optimised 
					80TB of HDD capacity for block volume and S3 compatible object storage 
				Snowball Edge Compute Optimised 
					42TB of HDD or 28TB NVMe capacity for block volume and S3 compatible object storage
				Usecases 
					large data migration 
					disaster recovery
			Snowcone 
				small portable computing anywhere 
				rugged secure withstands any harsh environments
				used for edge computing storage and data transfer
				DataSync agent pre-installed
				Snowcone 
					8TB of HDD Storage 
				Snowcone SSD 
					14TB of SSD storage 
				use it when we have less space 
				must provide ur own battery/cables 
				can be sent to AWS offline or connect it to internet and use AWS DataSync to send data 
			Snowmobile
				transfer exabytes of data (1EB = 1000PBs = 1,000,000TBs)
				each have 100PB capacity
				high security, temperature controlled, GPS and 24/7 video surveilance
				Better than snowball if u transfer more than 10PB 
			Usage process	
				request device from AWS console for delivery
				Install snowball client/AWS OpsHub on your servers
				connect device to servers and copy files using client
				ship back to AWS 
				data loaded into S3 bucket
				Snowball is completely wiped
			Edge Computing 
				process data while it's being created on an 
				edge location(anything that doesn't have internet, far from cloud)
				we setup snowball edge/Snowcone device to do edge computing 
				Usecases 
					Preprocess Data
					Machine learning at the edge 
					Transcoding media streams 
				Snowcone & snowcone SSD (smaller)
					2 CPUs, 4GB of memory, wired or wireless access
					USB-C power using a cord or optional battery 
				Snowball Edge - Computing Optimised 
					104 vCPUs, 416 GiB of RAM 
					optional GPU (useful for video processing or machine learning)
					28TB NVMe or 42TB HDD usable storage 
					Storage Clustering available(upto 16 nodes)
				Snowball Edge - Storage Optimised 
					upto 40 vCPUs, 80 GiB of RAM, 80TB storage
				All can run EC2 Instances & AWS Lambda functions (aws IoT Greengrass)
				Long-Term deployment options: 1 and 3 years discounting price
			AWS OpsHub 
				A software u install on ur computer/laptop to manage  ur Snow Family Device
				Unlocking and configuring single or clustered devices 
				Transfering files 
				Launching and managing instances running on Snow Family Device
				monitor device metrics 
				launch compatible AWS services on your devices 
			Snowball into Glacier 
				cannot import into Glacier directly
				must use S3 incombination with an S3 kifecycle policy
		Amazon FSx 
			Launch 3rd party high-performance file systems on AWS 
			fully managed
			FSx File System Deployment Options 
				Scratch File System
					Temporary Storage
					Data is not replicated(doesn't persist if server fails)
					High Burst(6X faster, 200MBps per TiB)
					shorterm processing, optimise costs 
				Persistent File System
					long term storage 
					Data is replicated within same AZ
					Relace failed files within minutes 
					long-term processing sensitive data			
			FSx for lustre
				type of parallel distributed file system for large scale computing 
				name is derived from Linux and Cluster
				Machine Learning, High Performance Computing (HPC)
				Video processing, financial modeling, electronic design automation
				Scales upto 100s GB/s, milions of IOPS, sub-ms latencies 
				Storage options	
					SSD 
						low latency, IOPS intensive workloads, small & random file operations 
					HDD
						throughput-intensive workloads, large and sequential file operations
				Seamless integration with S3 
					Can read S3 as a file system (through FSx)
					Can write output of computations back to S3 (through FSx)
				Can be used from on-premises servers(VPN or Direct Connect)		
			FSx for Windows (File Server)
				fully managed file system share drive 
				Supports SMB protocol & Windows NTFS 
				Microsoft Active Directory integration, ACLs, user quotas
				Can mount on Linux EC2 instance 
				Supports Microsoft's Distribution File System(DFS) Namespaces(group files across multiple FS)
				Scale upto 10s of GB/s milions of IOPs, 100s of PB of data 
				Storage options 
					SSD 
						latency sensitive workloads 
					HDD 
						broad spectrum of workloads
				Can be accessed from your on-prem infra(VPN or Direct Connect)
				can be configured to be Multi-AZ
				Data is backed-up daily to S3 
			FSx for NetApp ONTAP 
				managed NetApp ONTAP on AWS 
				move from ONTAP or NAS to AWS 
				works with 
					Linux,windows,MacOS
					VMWare Cloud on AWS 
					Amazon workspaces & App stream 2.0
					Amazon EC2,ECS and EKS 
				Storage shrinks and grows automatically
				Snapshots, replications, low cost, compression and data de-duplication
				Point-in-time instantaneous Cloning(helpful for testing new workloads)			
			FSx for OpenZFS
				managed OpenZFS on AWS 
				File system compatible with NFS(v3,v4,v4.1,v4.2)
				Move workloads running on ZFS to AWS 
				works with 
					Linux,windows,MacOS
					VMWare Cloud on AWS 
					Amazon workspaces & App stream 2.0
					Amazon EC2,ECS and EKS 
				upto to 1,000,000 IOPS with <0.5ms latency
				Snapshots, compression and low cost 
				Point-in-time instantaneous Cloning(helpful for testing new workloads)
		AWS Storage Gateway
			Bridge between on-premises data and cloud data 
			Use cases
				disaster recovery
				backup & restore
				tiered storage
				on-premise cache & low latency files access
			Types of Storage Gateway 
				S3 file gateway 
					all classes except Glacier 
					Configured s3 buckets are accessible using NFS and SMB protocol
					Most recently used data is cached in file gateway
					Transition to S3 Glacier using lifecycle policy 
					Bucket access using IAM roles for each File Gateway
					SMB protocol has integration with Active Directory(AD) for user authentication 				
				FSx file gateway
					Native access to Amazon FSx for windows file server 
					Local cache for frequently accessed data 
					Windows native compatability (SMB,NFTS,Active Directory)
					useful for group file shares and home directories
				Volume gateway
					Block storage using iSCSI protocol backed by S3
					Backed by EBS snapshots which can help restore on-premise volumes 
					Cached volumes 
						low latency access to most recent data 
					Stored Volumes	
						entire dataset is on premise, scheduled backups to S3
					usefull for backup of on premise server volumes 
				Tape gateway
					Some companies have backups using physical tapes 
					Tape Gateway uses same process but in cloud 
					Virtual Tape Library(VTL) backed by Amazon S3 and Glacier
					Backup data using existing tabe-based processes(and iSCSI interface)
			These gateways has to be installed on corporate datacentre
			Hardware appliance
				Using storage gateway means you need on-premise vitualization 
				Otherwise, u can use Storage Gateway Hardware Appliance
				works with 
					File gateway
					Volume gateway
					Tape gateway
				has required CPU, memory, network, SSD cache resource
				helpful for daily NFS backups in small data centers 
		AWS Transfer Family
			fully managed service for file transfers into and out of S3 or EFS using "FTP" protocol
			Supported protocols 
				AWS Transfer for FTP 
				AWS Transfer for FTPS (File transfer protocol over SSl)
				AWS Transfer for SFTP (Secure File transfer protocol)
			Pay per provisioned endpoint per hour + data transfers in GB 
			Store and manage user credentials within service 
			Integrate with existing authentication systems (MS Active Directory, LDAP, Okta,Amazon Cognito, custom)
			Usage 
				sharing files 
				public datasets 
				CRM,ERP
		AWS DataSync 
			Move large amount of data to and from 
				on-premise or other cloud to AWS(needs agent)
				AWS to AWS (different storage services) (no agent needed)
			Can synchronize to 
				Amazon S3(including Glacier)
				Amazon EFS 
				Amazon FSx 
			Replication tasks can be scheduled hourly, daily or weekly
				not have continous sync 
			"File permissions and metadata are preserved (NFS,POSIX,SMB)"
			One agent task can use 10 Gbps, can setup bandwidth limit

		Quiz 
			You need to move hundreds of Terabytes into Amazon S3, then process the data using a fleet of EC2 instances.
			You have a 1 Gbit/s broadband. You would like to move the data faster and possibly processing it while in transit. 
				Snowball Edge 
	Decoupling Applications 
		SQS 
			Unlimited throughput and no of messages in queue
			Default retention of messages: 4 days, max of 14 days 
			Low latency (<10ms on publish and receive)
			Limitation of 256KB per message sent 
			Types 
				Standard
					At-least once delivery
					Best effort ordering
				FIFO
					First in first out 
					Exactly once processing
			Can have duplicate messages (at least once delivery, occasionally)
			Can have out of order messages (best effort ordering)
			Can scale autoscaling group with Queue length
			Encryption
				In-flight with HTTPS API 
				AT-rest KMS keys 
				Client side encryption
			Access control using IAM Policy 
			SQS Access Policies (similar to S3 bucket policies)
			Message Visibility Timeout
				after message is pulled by one consumer, it becomes invisible to other consumers 
				default 30sec (within message has to be processed)
				if msg is not processing within timeout, it will be processed twice
				ChangeMessageVisibility API to get more time 
			Long Pooling 
				when consumer requests, it can optionally wait for messages to arrive if there are none 
				can wait 1 to 20sec 
				long pooling preffered to short pooling 
				can enable at queue level or API level using WaitTimeSeconds
			FIFO 
				Limited throughput 300,sg/s without batching, 3000 msg/s with 
				Exactly once send capability (by removing duplicates)	
				ordering by message group id (all messages in same group are ordered)	
				Deduplication using a Deduplication id or content based Deduplication
		SNS 
			one msg to many receivers 
			pub/sub 
			Many AWS services can send msgs directly to SNS 
			publish 
				Topic publish (using SDK)
					create topic 
					create subscription (or many)
					publish to topic 
				Direct publish (for mobile apps SDK)
					create platform app
					create a platform endpoint 
					publish to platform endpoint
			Encryption
				In-flight with HTTPS API 
				AT-rest KMS keys 
				Client side encryption
			Access control using IAM Policy 
			SNS Access Policies (similar to S3 bucket policies)
				useful for cross-account access to SNS topics
				useful to allow other services(S3..)  to write to SNS topic
			SNS + SQS: Fan Out
				push once to SNS, receive in all SQS queues that are subscribers
				Cross-Region Delivery
					works with SQS queues in other regions 
				SNS to S3 through Kinesis Data Firehose 
			FIFO topic
				ordering by message group id (all messages in same group are ordered)	
				Deduplication using a Deduplication id or content based Deduplication
				SNS FIFO + SQS FIFO: Fan Out
			Message Filtering 
				JSON policy to filter msgs sent to SNS topics subscription
				if subscription doesn't have filter policy, it receives every msg
			Standard
				best effort msg ordering 
				at-least once delivery
				highest throughput 
				subscription protocols
					SQS, Lambda, HTTP, SMS, email, mobile app endpoint
			FIFO 
				Strictly preserved msg ordering 
				Exactly once msg Delivery
				subscription protocols
					SQS
		Kinesis 
			collect, process and analyze streaming data in real-time 
			Kinesis Data streams 
				capture, process and store data streams
				shards
					data is split into no of shards 
					must define no of shards 
					shards are going to define streaming capacity
				Record
					partition key 
						determine which shard the record will go 
					Data blob
						value itself 
						upto 1MB
				Retention 1-365 days
				ability to reprocess (replay) Data
				Once data is inserted in Kinesis, it can't be deleted (Immutable)
				Data that shares the same partition goes to same shard
				producers 
					AWS SDK, Kinesis producer Library(KPL), Kinesis Agent 
				Cunsumers 
					write your own 
						Kinesis Client Library(KCL), AWS SDK 
					Managed
						AWS Lambda, Kinesis Data Firehose, Kinesis Data Analytics
				Capacity Mode
					Provisioned mode
						choose no of shards provisioned, scale Manually or using API 
						each shard gets 1MB/s in 
						each shard gets 2MB/s out 
						pay per shard provisioned per hour 
					On-demand mode 
						no need to provision or manage capacity
						Default capacity provisioned 4MB/s in 
						Scales automatically based on observed throughput peak during the last 30 days 
						Pay per stream per hour & data in/out per GB 
				Control access using IAM 
				Encryption
					in-flight using HTTPS 
					at rest using KMS 
					can have client side encryption
				VPC endpoints are available for Kinesis to access within VPC 
				monitor API calls using CloudTrail
			Kinesis Data firehose 
				load data streams into AWS data stores
				fully Managed
				send data into 
					AWS: Redshift, S3 and OpenSearch 
					3rd party: Splunk/mongoDB/DataDog etc 
					custom: any http endpoint
				pay for data go through Firehose 
				Near-realtime
					write data in batches
				support
					many data formats, conversions and transformations 
					can write custom transformations using AWS Lambda 
				can send failed or all data to a backup S3 Bucket
			Kinesis Data streams vs Kinesis Data firehose
				Data streams
					streaming service to ingest at scale
					write custom code(producer/consumer)
					Real-time 
					Manage scaling (shard spliting/merging)
					Data storage for 1 to 365 days 
					support replay data
				Kinesis Data firehose
					Load streaming data into S3/Redshift/OpenSearch/3rd party/custom HTTP
					fully managed
					Near real-time (buffer time min 60sec)
					Automatic scaling 
					No data storage
					doesn't support replay 	
			Kinesis Data Analytics 
				analyze data streams with SQL or Apache Flink
			Kinesis Video streams
				capture, process and store video streams
		Amazon MQ 
			managed msg broker service for RabbitMQ and ActiveMQ (on-prem technologies)
			doesn't scale as much as SQS,SNS 
			runs on servers, can run in Multi-AZ with failover 
			has both queue feature (~SQS) and topic feature (~SNS)
			Failover 
				use Amazon EFS (can be mount on multi-AZs)
			Amazon MQ supports industry-standard APIs such as JMS and NMS and
			protocols for messaging, including AMQP, STOMP, MQTT, and WebSocket.

	Containers 
		Amazon ECR 
			store container images
			private repository for docker Containers
			public repository (Amazon ECR Public Gallery gallery.ecr.aws)
			supports image vulnerability scanning, versioning, image tags, image lifecycle.
		Amazon Elastic Container Service (ECS)
			amazon own container platform
			EC2 Launch Type
				launch containers on AWS =  launch ECS Tasks on ECS clusters 
				you must provision & maintain infra (EC2s)
				Each EC2 instance must run ECS Agent to register in ECS cluster
			Fargate Launch Type
				u do not provision infra 
				Serverless
				ti scale just increase no of tasks
			IAM Roles 
				EC2 instance profile(EC2 launch type only)
					used by ECS agent
					make API calls to ECS 
					send container logs to CloudWatch
					pull docker image from ECR
					reference sensitive data in Secrets manager or SSM Parameter store
				ECS Task Role 
					allows each task to have a specific role 
					use different roles for different ECS services you run 
					Task Role defined in task defination
			Load Balancer integration
				Application Load Balancer 
					supported and works for most usecases
				Network Load Balancer
					recommended only for high throughput/high perf use cases
					or pair it with AWS private link 
				Classic Load Balancer
					supported but not reccomended
					no Advanced Features
					no Fargate
			Data Volumes 
				Mount EFS systems on ECS tasks 
				Works for both ECS and Fargate launch types 
				Tasks running in any AZ will share the same data in EFS file system
				Fargate + EFS = Serverless
				use cases 
					persistent multi-AZ shared storage for Containers
				S3 can be mounted as a file system
			ECS Service Autoscaling 
				uses AWS Application Autoscaling
				ECS service avg CPU utilization
				ECS service avg memory utilization
				ALB request count per target 
				Target tracking 
					scale based on target value for specific CloudWatch metric
				Step scaling 
					scale based on a specified CloudWatch Alarm 
				Scheduled scaling
					scale based on date and time 
				EC2 launch type 
					Auto Scaling group scaling 
						scale based on CPU utilization
						Add EC2 over time 
					ECS Cluster Capacity provider 
						recommended
						used to automatically provision and scale the infra for your ECS Tasks 
						Capacity Provider paired with Auto Scaling Group
						Add EC2 when u r missing capacity (CPUm,RAM..)
			Solutions Architecture
				ECS Tasks invoked by EventBridge

		Amazon Elastic Kubernetes Service (EKS)
			open source system for automatic deployment, scaling and Management of containerized app			
			managed Kubernetes cluster in AWS 
			supports 
				EC2 
					if u want to deploy a worker nodes
				Fargate 
					to deploy Serverless
			Node Types 
				managed node groups 
					creates and manages Nodes (EC2) for u 
					Nodes are part of an ASG managed by EFS
					Supports on-demand or spot instances
				Self managed groups
					nodes created by u and registered to EKS cluster and managed by an ASG 
					u can use prebuilt AMI - Amazon EKS optimised AMI 
					Supports on-demand or spot instances
				AWS Fargate 
					no maintainance required 
					no nodes managed 
			Data Volumes 
				Need to specify StorageClass manifest on ur EKS cluster 
				Leverages container storage interface (CSI) compliant driver 
				support for 
					EBS,EFS, FSx for Lustre and NetApp ONTAP
		AWS Fargate
			Serverless container platform
			works with ECS and EKS 

		AWS App Runner 
			easy to deploy web apps and APIs at scale
			No infrastructure experience required
			start with ur source code or container image 
			automatically builds and deploys web app
			automatically scaling, high available, load balancer, encryption 
			VPC access point 
			Connect to database, cache and message queue services 
			use case 
				web apps, APIs, microservices, rapid production deployments 
	Serverless 
		AWS Lambda 
			pay per request and compute time 
			Integrated with whole AWS suite and many programming languages
			monitoring with CloudWatch
			up 10GB of RAM per function
			Increasing RAM will also improve CPU and network
			language support 
				Node.js 
				Python 
				Java 
				C# (.NET Core)
				Golang 
				C#/powershell
				Ruby 
				Custom Runtime API(example Rust)
				Lambda container Image
					container image must implement Lambda Runtime API
					ECS/Fargate is preffered
			Lambda Limits - per Region 
				Execution
					Memory allocation 
						128MB - 10GB 
					Maximum execution time 
						900sec(15min)
					Environment Variables 
						4KB 
					Disk capacity in "function container" (in /temp)
						512 to 10GB 
					concurrency executions: 1000(can be increased)
				Deployment 
					deployment size (.zip)
						50MB 
					Size of uncompressed deployement (code+dependencies)
						250MB 
					can use /temp to load other files at startup 
					Size of Environment Variables 
						4KB 
			
			Edge funtion
				A code that u write and attach to CloudFront distributions 
				runs close to users to minimize latency 
				don't have to manage any servers, deployed globally
				usecase: customize CDN content
				fully serverless
				Types 
					CloudFront functions 
						light-weight functions written in Javascript
						high-scale latency-sentive CDN customizations 
						sub-ms startup times, "milions" of requests/sec
						execution time <1ms
						used to change "viewer" requests and responses
							viewer request 
								after cloudfront receives a request from viewer
							viewer response 
								before cloudfront forwards response to viewer
						native feature (manage code within cloudfront)
					Lambda@Edge 
						Lambda functions written in NodeJS or Python
						scales to "1000s" of requests/sec 
						execution time 5-10sec
						used to change "cloudfront" requests and responses
							viewer request 
								after cloudfront receives a request from viewer
							viewer response 
								before cloudfront forwards response to viewer
							origin request 
								before cloudfront forwards the request to origin 
							origin response
								after cloudfront receives the response from origin 
						author ur function in one region, the CloudFront replicates it to all locations 
			Lambda by default
				lambda will launch outside of ur VPC (AWS owned VPC)
				it cannot have access to resources in ur VPC 
			Lambda in ur VPC 
				must define VPC id, subnets and security groups 
				Lambda with RDS proxy 
					must be deployed in ur VPC, because RDS proxy is never publicly accessible
		DynamoDB 
			fully managed, available with replication across Multi-AZs
			NoSQL database, not a relational db, with transaction support
			milions of requests/sec, trilions of rows,100s of TB of storage
			fast and consistent performance(single digit millisec)
			Standard and Infrequent Access (IA) Table Class
			Made of tables, each has Primary Key(must define at creation time)
			each table has infinite no of items(=rows)
			each item has attributes (can be added over time -can be null)
			max size of item is 400KB 
			data types
				scalar types 
					string
					number
					binary
					boolean
					null
				Document type 
					list
					Map 
				set types 
					string set, number set,binary set 
			u can "rapidly evolve schemas"
			primary key = partition key + sort key(optional)
			Read/Write Capacity Modes 
				Provisioned Mode (Default)
					u specify no of reads/writes per sec 
					pay for provisioned read capacity units (RCU) and write capacity units (WCR)
					possibility to add auto-scaling mode for RCU and WCU 
				On-demand Mode 
					scale automatically
					pay for what u use, more expensive
					great for "unpredictable" workloads and "steep spikes"
			DynamoDB Accelerator(DAX)		
				fully managed highly available, seamless in-memory cache for DynamoDB 
				Help solve read congestion by caching 
				micriosecond latency for cached data 
				5min TLL for cache (Default)
			Stream processing 
				ordered stream of item level modifications (create/update/delete)
				use cases 
					react to changes in realtime
					real-time usage Analytics
					implement cross region replication 
					invoke AWS lambda on changes in table 
				DynamoDB streams 
					24hr retention 
					limited no of consumers 
					process using AWS lambda triggers, or DynamoDB Stream Kinesis adapter 
				Kinesis Data streams
					1 year retention
					high no of consumers 
					process using AWS lambda, Kinesis data Analytics, Kinesis Data firehose, AWS Glue
			DynamoDB Global Tables 
				two way replication between tables
				table accessible with low latency in multiple regions
				Active-Active replication 
				can read and write to tables in any region 
				must enable DynamoDB streams
			DynamoDB Time To Live (TTL)
				automatically deletes items after an expiry timestamp
				use case: web session handling 
			Backups for Disaster Recovery 
				continuos backups using point-in-time recovery(PITR)
					optionally enabled for last 35 days 
					recovery creates new table
				On-demand backups 
					full backups for long term retention, until explicitely deleted 
					can be configured and managed in AWS Backup (enables cross region copy)
					recovery creates new table
			Integration with S3
				export to S3 (must enable PITR)
					works with any point of time within last 35 days 
					doesn't affect the read capacity of table 
					export in DynamoDB JSON or ION Format 
				Import from S3 
					import CSV, DynamoDB JSON or ION format
					doesn't consume any write capacity
					creates a new table 
		API Gateway
			Lambda + API Gateway: no infra to manage 
			support for Websocket
			Handle api versions,environments and security(Authentication & Authorization)
			create API keys, handle request throttling
			Swagger/Open API import to quickly define APIs 
			Transform and validate requests and response 
			Generate SDK and API specifications
			Cache API responses 
			Integrations High level
				lambda function
				HTTP 
				AWS Service 
					Expose any AWS API
					ex:post a message to SQS
			Endpoint Types 
				Edge Optimized(default)
					for global clients 
					request are routed through CloudFront edge locations 
					API Gateway still lives in only one region
				Regional 
					for clients in same region 
					Cloud Manually combine with CloudFront
				private
					can only be accessed from ur VPC using an interface VPC endpoint(ENI)
					use a resource policy to define access
			Security
				User Authentication
					IAM Roles 
					Cognito(Identity for external users)
					Custom Authorizer(ur own logic)
				Custom Domain Name HTTPS 
					security through integrations with AWS certificate manager (ACM)
					if using Edge-Optimized endpoint, then certificate must be in "us-east-1"
					if using Regional endpoint, certificate must be in API Gateway region
					Must setup CNAME or A-alias record in Route 53
		AWS Step functions
			build serverless visual workflow to orchestrate ur lambda functions 
			features 
				sequence
				parallel 
				conditions 
				timeouts 
				error handling 
			can integrate with EC2, ECS, on-prem severs, API gateway, SQS etc 
			possibility of implementing "human approval" feature
			use cases 
				order fulfillment 
				data processing 
				web Applications
				any workflow 
		AWS Cognito
			give users identity to interact with our web or mobile apps 
			Cognito User Pools 
				create serverless database of users for ur mobile/web apps
				simple login 
				password reset 
				Email & Phone no verification
				MFA
				Federated Identities: users from Facebook, Google, SAML 				
				integrates with API Gateway & Application Load Balancer				
			Cognito Identity Pools (Federated Identity)
				get Identities for users so they can obtain temporary AWS credentials
				Security Token Service (STS) 
					enables you to request temporary, limited-privilege 
					credentials for IAM users or for federated users
				users source can be Cognito users pools, 3rd party logins etc
				users can then access AWS services directly or through API gateway
				IAM policies applied to credentials are defined in Cognito 
				they can be customised based on user_id for fine grained control
				Default IAM roles
					for authenticated and guest users 
				Row level security in DynamoDB
			cognito vs IAM 
				hundreds of users 
				mobile Users
				authenticate with SAML
		Amazon S3 
		AWS SNS & SQS 
		AWS Kinesis Data Firehose 
		Aurora Serverless
		Fargate 
	Databases in AWS 
		RDMS 
			SQL/OLTP 
			RDS Aurora
			great for joins 
		NoSQL
			no joins 
			no SQL 
			DynamoDB
			ElasticCache 
			DocumentDB 
				for MongoDB 
				used to store, query and index JSON data
				fully managed,highly available with replication across 3 AZ 
				grows in increments of 10GB upto 64TB 
				scales to workloads with milions of requests per seconds				
			Keyspaces
				Apache Cassandra is an open-source NoSQL distributed database
				managed apache Cassandra compatible database 
				serverless, scalable 
				automatically scales tables up/down based on app traffic 
				tables are replicated 3 times across multiple AZ 
				queries using Cassandra Query Language(CQL)
				Single digit milisec latency at any scale, 1000s of requests/sec 
				Capacity
					On-demand 
					provisioned with auto-scaling 
				Encryption,backup,point-in-time recovery(PITR) upto 35 days 
				use case 
					store IoT device info, time series data 
		Object store 
			S3 
		Data warehouse
			Redshift 
			Athena 
			EMR 
		Search 
			OpenSearch
		Graphs 
			Neptune 
				fully managed graph database 
				ex:social network
				highly available across 3 AZ with upto 15 read replicas 
				can store upto billions of relations and query graph with milisec latency
				great for knowledge graphs, recommendations Engine, social networking			
		Ledger 
			Amazon Quantum Ledger Database (QLDB)
				book recording financial transactions
				fully managed, serverless, highly available replication across 3 AZ 
				used to review history of changes to app data over time 
				Immutable system 
					no entry can be removed or modified 
					cryptographical verifiable 
				2-3x better performance than common ledger blockchain frameworks,manipulate data using SQL
				Difference with Amazon Managed Blockchain 
					no decentralization component in QLDB 
					in accordance with financial regulation rules 
		Time series 
			Amazon Timestream 
				fully managed, serverless, fast, scalable time series database
				store and analyze trillions of events per day 
				1000s times faster & 1/10th cost of relational database
				Scheduled queries, multi-measure records, SQL compatability
				Data storage tiering 
					recent data stored in memory
					historical data kept in cost-optimized storage 
				Built-in time series analytics functions 
					identify patterns in near real-time 
				encryption in trasit and at rest 
				usecase 
					IoT apps
					operational apps 
					real-time analytics
				
	Data Analytics
		Athena
			Serverless query service to  analyze data in S3 
			Use SQL to query files (built on Presto)
			supports 
				CSV,JSON
				ORC,Avro and Parquet
			pricing: 5$ per TB of data scanned
			commonly used with AWS Quicksight for reporting/dashboards 
			Use cases: Business Intelligence, analytics, reporting,
				analyze abd query VPC flow logs, ELB logs, CloudTrail logs etc 
			Perf Improvement
				use columnar data for cost-savings(less scan)
					Apache Parquet or ORC is recommended 
				use Glue to convert ur data to Parquet or ORC 
				Compress data 
					bzip2,gzip,Iz4,snappy,zlip,zstd etc
				partition data sets in S3 
					for easy query on virtual colums 
					ex: s3://bucket/pathToTable/parquet/year=1901/month=1/day=1/
				Use larger files 
					>128MB to minimize overhead instead of many smaller files 
			Federated Query 
				allows u to run query across data stored in relational,non-relational,object 
				custom data sources(AWS or on-prem)
				use Data Source Connector that run on AWS Lambda to run federated query 
				store results back to S3 
		Redshift
			based on PostgresSQL, but its not OLTP 
			it OLAP online analytics processing 
			10x better performance than data warehouses, scale to PBs of data
			Columnar storage of data (instead of rows) & parallel query engine 
			Pay per instances provided 
			SQL interface for queries
			BI tools like Quicksight or Tableau integrate with it 
			vs Athena
				it loads data into it 
				faster queries 
				joins &	aggregations (thanks to indexes)
			Leader node 
				for query planning and results aggregation
			Compute node 
				for performing queries and send results to leader 
			u provision node size in Advance
			Snapshots & disaster recovery
				has Multi-AZ mode for some clusters
				snapshots are point in time backups of a cluster 
				stored internally in S3
				snapshots are incremental (only changes are saved)
				automated: with retention
				manual:retained until u delete
				can configure to automatically copy snapshots to another region
			Loading data to Redshift
				Kinesis Data firehose 
					through S3 COPY 
				S3 using COPY command 
					Internet 
						without enhanced VPC routing
					Through VPC 
						With enhanced VPC routing
				EC2 Instance 
					JDBC driver 
						better to write data in batches 
			Redshift Spectrum 
				Query S3 without loading 
				lot more compute power than redshift 
				must have redshift cluster to query 
				query is submitted to 1000s of Redshift Spectrum nodes 
		
		Amazon OpenSearch
			successor to Amazon ElasticSearch 
			can search any field even partial matches 
			can use as a complement to another database 
			modes 
				managed cluster 
				serverless cluster
			doesn't natively support SQL (can be enabled via plugin)
			Ingestion from Kinesis Data firehose, AWS IoT, CloudWatch logs
			Security 
				Cognito & IAM 
				KMS, TLS 
			OpenSearch Dashboards (visualization)
		Amazon EMR (Elastic Map Reduce)
			creates Hadoop clusters (Big Data) to analyze and process vast amount of data 
			made of 100s of EC2 instances 
			bundled with Apache spark, HBase, Presto, Flink 
			take care of all provisoning and configuration 
			Auto-scaling and integrated with spot instances 
			use cases
				data processing 
				machine learning 
				web indexing 
				big data 
			Node Types 
				Master Node 
					manage cluster, coordinate, manage health 
					long running
				Core Node 
					Run tasks and store data 
					long running
				Task Node(optional)
					Just to run tasks 
					usually spot 
				purchasing options 
					on-demand instances
					reserved min 1yr 
					spot instances 
			cluster types
				long-running cluster
				transient
					temporary cluster 
		Amazon Quicksight
			Serverless machine learning-powered Business Intelligence service 
			to create interactive dashboards
			use cases
				Business analytics
				Building visualization
				Perform ad-hoc analysis
				get Business insights using data 
			in-memory computations using SPICE engine 
				only if data is imported into Quicksight
			Enterprise edition 
				can setup Column level security(CLS)
			Integrations 
				RDS, Aurora, Redshift
				Athena, S3, OpenSearch
				Timestream
				also 3rd party Data sources (SaaS) & Databases
				can import data source files 
			Dashboards & Analysis
				Define users(standard version) & groups (Enterprise version)
					users and groups only exist in Quicksight, "not IAM"
				dashboard
					is read-only snapshot of an analysis that u can share 
					preserves configuration of analysis(filtering,parameters,contorls,sort)
				can only share the analysis with users or groups 
				to share a dashboard, u must first publish it 
				users who can see dashboards can also see underlying data 
		AWS Glue
			managed extract transform and load (ETL) service 
			serverless
			use case 
				convert data into parquet format
			Glue Data Catalog 
				Glue Data crawler write all metadata into Glue Data Catalog
			Glue Job Bookmarks 
				prevent reprocessing of old data 
			Glue Elastic views
				Combine and replicate data across multiple data sources using SQL
				No custom code, Glue monitors for changes in source data, serverless
				Leverages virtual table (materialized view)
			Glue DataBrew
				clean and normalize data using pre-built transformations
			Glue Studio
				new GUI to create, run and monitor ETL jobs 
			Glue Streaming ETL (built on Apache Spark Structured Streaming)
				compatable with 
					Kinesis Data streams
					Kafka 
					MSK (managed kafka)
		AWS Lake Formation 	
			central place to have all data for analytics
			discover,cleanse, transform and ingest data into ur Data Lake 
			out-of-the-box source blueprints 	
				S3,RDS,Relational & NoSQL
			Fine grained access control for ur app (row & column level)
			Built on top of Glue 
			use case 
				centralized permissions
		Kinesis Data Analytics
			for SQL apps
				Real-time analysis on Data Streams & Firehose using SQL
				Add reference data from S3 to enrish streaming data 
				Fully managed, no servers provision 
				Automatic scaling 
				Pay per actual consumption rate 
				output
					Kinesis Data streams 
						create streams out of real-time analytics queries
					Kinesis Data Firehose
						send analytics query results to destinations
				Use cases 
					Time series analytics
					Real-time Dashboards
					real-time metrics 
			for Apache Flink 
				Use flink (Java,Scala or SQL) to process and analyse streaming data 
				Run any Apache Flink app on a managed cluster on AWS 
					provisioning compute resources,parallel computations,automatic scaling 
					app backups (implemented as checkpoints and snapshots)
					read from Kinesis Data streams & Amazon MSK
					Flink does not read from Firehose (use Kinesis Data analytics for SQL instead)
		Amazon Managed Streaming for Apache Kafka (Amazon MSK)
			Alternative to Kinesis
			fully managed apache kafka on AWS 
				create, update and delete clusters
				MSK creates & manages Kafka brokers nodes & Zookeeper nodes for u 
				Deploy MSK in ur VPC, multi-AZ(upto 3)
				Automatic recovery from apache kafka failures 
				data is stored on EBS volumes as long as u want
			MSK serverless
				run apache kafka without managing capacity
				automatically scales compute and storage 
			Kinesis Data streams vs Amazon MSK 
				Kinesis
					1MB size limit 
					data streams with shards 
					Shard spliting and merging
					TLS in-flight encryption
					KMS at rest encryption
				MSK 
					default 1MB, configure for higher(ex:10MB)
					kafka topics with Partitions 
					can only add partitions to a topic 
					PLAINTEXT or TLS in-flight encryption
					KMS at rest encryption
					can keep data as long as u want
	Machine Learning
		Rekognition 
			find objects,people,text,scenes in images and videos using ML 
			Facial analysis and facial search to do user verification and people count 
			create database of familiar faces or compare against celebrities
			use cases 
				labeling 
				Content Moderation 
					detect content that is inappropriate, unwanted, or offensive (images and videos)
					set min confidence threshold for items that will be flagged 
					flag sensitive content for manual review in Amazon Augumented AI (A2I)
				text detection
				Face detection and analysis
				Face search and verification
				celebrity recognition
				Pathing (ex:sport game analysis)
		Amazon Transcribe 
			convert speech to text 
			uses deep learning process called automatic speech recognition (ASR)
			Automatically remove Personally Identifiable information(PII) using redaction 
			supports automatic language identification for multi-lingual audio 
		Amazon Polly 
			Turn text to speech 
			Lexicon 
				customize the pronounciation of words with pronounciation lexicons 
				Stylized words : St3ph4ne => Stephane 
				Acronyms AWS => "Amazon Web Services"
			Speech Synthesis Markup Language (SSML)	
				enables more customization 
				emphaisizes specific words or phrases 
				using phonetic pronounciation
				including breathing sounds, whispering 
				using Newscaster speaking style 
		Amazon Translate 
			localize content such as websites and apps 
			for international users, to easily translate large volumes of text efficiently 
		Amazon Lex & Connect 
			Lex 
				powers alexa 
				Automatic Speech recognition (ASR) to convert speech to text 
				Natural language Understanding to recognize the intent of text, callers 
				Helps to build chatbots and call center bots 
			Connect 
				Receive calls, create contact flows, cloud based virtual contact center
				Can integrate with other CRM systems or AWS 
				No upfront payments, 80% cheaper than call center solutions 
		Amazon Comprehend
			Natural language processing (NLP)
			serverless
			uses ML to find insights and relationships in text 
				language of text 
				extract key phrases, people, brands or events 
				understand how positive or negative the text is 
				Analyze text using tokenization and parts of speech 
				automatically organizes a collection of text file by topic
			use cases 
				analyze customer interactions to find positive or negative experience
				create and group articles by topic that Comprehend will uncover 
		Amazon Comprehend Medical 
			detect and returns useful info in unstructured clinical text 
				physician notes 
				discharge summaries 
				test results 
				case notes 
			Uses NLP to detect Protected Health information(PHI) - DetectPHI API
		Amazon SageMaker 
			fully managed service for Developers/data scientists to build ML Models 
		Amazon Forecast 
			ex: predict future sales of a product
			50% more accurate than looking at data itself 
			reduce forcasting time from months to hours 
		Amazon Kendra 
			Document search service powered by ML 
			extract answers within a Document (text,pdf,HTML,powerpoint,MS Word,FAQs)
			knowledge indexing
			Natural language search capability
			ability to manually fine-tune search results(importance of data, freshness,custom) 
		Amazon Personalize
			personalized recommendations
			Integrates into existing websites,apps,SMS,email marketing systems
			implement in days 
		Amazon Textract
			extracts texts, handwriting and data from any scanned Documents using AI and ML 
	AWS Monitoring & Audit 
		CloudWatch Metrics 
			cloudwatch provides metrics for every service 
			metric is variable to monitor(CPUUtilization,networking)
			Metrics belongs to namespaces (every service have a namespace)
			Dimension is attribute of metric (instance_id,environment etc)
			upto 30 dimensions per metric 
			Metrics have timestamps
			can create CloudWatch dashboards of metrics 
			can create custom metrics (for RAM)
			Metric Streams 
				stream CloudWatch metrics to destination of ur choice 
				with near-real-time, low latency
				can filter metrics to only stream subset of metrics
		CloudWatch Logs 
			Log groups 
				arbitary name, usually represnts app name 
			Log stream 
				instances within app/log files/containers 
			can define log expiration policy (never,1 to 10yrs)
			encrypted by default
			can setup KMS encryption with ur own keys 
			CloudWatch Logs Insights
				query logs 
				can save queries and add them to CloudWatch Dashboards
			S3 Export 
				batch export 
				upto 12hrs to complete 
			Logs Subscription 
				stream real-time log events from CloudWatch
				Subscription filter
					filter log events 
				Cross-Account Subscription
					send log events to resources in different account
			Logs for EC2 
				need to run CloudWatch Agent on EC2 
				EC2 must have IAM permissions to send logs 
				Agent can run on on-premise also 
				CloudWatch Logs Agent 
					old version
					can only send to CloudWatch Logs 
				CloudWatch Unified Agent
					new version
					collect aditional system level metrics such as 
						RAM,CPU,Disk Metrics,Netstat,Processes,Swap space
					Centralize configuration using SSM Parameter Store 
		CloudWatch Alarms 
			to trigger Notifications for any metric 
			states 
				OK 
				INSUFFICIENT_DATA 
				ALARM
			period 
				length of time in seconds to evaluate metric 
			Alarm Targets 
				stop,terminate,reboot or recover an EC2 instance
				Trigger Auto Scaling Action 
				send Notification to SNS 
			Composite Alarms 
				monitors multiple alarms 
				AND and OR conditions 
			EC2 Instance Recovery 
				Instance check = check EC2 VM 
				System status = check underlying hardware
				Same private,public,Elastic IP,metadata,placement group
		Amazon EventBridge
			Schedule:
				Cron jobs
			Event pattern 
				event rules to react to service doing something
				ex:root signin event, send a Notification
			Trigger Lambda or send messages to SNS/SQS 
			Event Bus 
				default
				partner 
				custom 
					to send events from ur app 
				can be accessed by other AWS accounts using Resource-based policies
			can Archive events indefinitely or set period 
			can replay archived events 
			Schema Registry 
				EventBridge can analyze events from ur bus and infer the schema 
				Schema Registry allows u to download the code for ur app, that will know 
				in Advance how data is Structured in event bus 
				Schema can be versioned 
			Resource based policy 
				manage permissions to event bus 
				ex:allow deny events from another account/region 
		CloudWatch Container Insights 
			collect,aggregate, summurize logs and metrics from containers 
			available on 
				Elastic Container Service 
				Elastic Kubernetes Service
				Kubernetes on EC2 
				Fargate
		CloudWatch Lambda Insights
			monitoring and troubleshooting for serverless app running on lambda
			collects
				CPU,Memory,Disk,Network
				Cold starts and lambda worker shutdowns 
		CloudWatch Contributor Insights
			Analyze log data and create time series that display Contributor Data 
				metrics about top N-Contributors
				no of unique contributors and their usage 
			Works for any AWS generated logs 
			helps u find top talkers and who or what is impacting system perf 
		CloudWatch Application insights
			automated dashboards that show potential problems with monitoring apps 
			apps running on EC2 with select technologies only 
				Java,.NET,Microsoft IIS, Database
			can use other AWS services (add those also in dashboards)
			Enhanced Visibility to ur app health
			Findings and alerts are sent to EventBridge and SSM OpsCenter 
		Amazon CloudTrail 
			provides governance,compliance and audit for ur AWS account
			enabled by default
			get history of events/API calls made within AWS account by
				Console
				SDK 
				CLI 
				AWS services 
			can put logs into CloudWatch or S3 
			trail can be applied to All Regions(default) or single region 
			if a resource is deleted in AWS, investigate CloudTrail first
			CloudTrail Events 
				Management Events 
					Operations performed on resources in AWS 
					by default logged 
					can separate read events from write events 
				Data Events 
					by default not logged 
					S3 object level activity,can separate read events from write events 
					AWS lambda execution activity
				Insights Events 
					to detect unusual activity in ur account
					example
						inaccurate resource provisioning 
						hitting service limits 
						Burst of IAM actions 
					continuously analyzes write events 
			Events Retentions 
				stored for 90 days in CloudTrail
				for more period, log to S3 
			Intercept API calls
				API calls are logs in CloudTrail
				same are logged in EventBridge as an event 
				can send Notifications to SNS 
		AWS Config 
			auditing and recording compliance of AWS resources
			records configurations and changes over time 
			Questions that can be solved 
				is there unrestricted SSH access to my security groups 
				does my bucket has public Access
				ALB configuration changes over time 
			can receive alerts to any changes 
			per-region service 
			can store configuration data in S3 
			Config rules 
				AWS has over 75 config rules 
				can create custom rule 
					ex:if each ec2 instance is t2.micro
				Rules can triggered or evaluated 
					for each config change 
					at regular intervals 
			pricing 
				$0.003 per configuration recorded per region 
				$0.001 per config rule evaluated per region
			Remediations 
				Automate remediation for non-compliant resources using SSM Automation Documents 
				can create custom Automation Documents 
				can set retries if resource is not-compliant after auto Remediations
			Notifications
				EventBridge to trigger Notification when resource is non-compliant
				can send configuration changes and compliance state Notifications to SNS 
				
	IAM Advanced
		AWS Organizations 
			Global service
			manage multiple AWS accounts
			main account is Management account
			other accounts are member accounts
			member accounts can only be part of one Organization
			Consolidated Biling across all accounts - Single payment method 
			pricing benifits from aggregated usages 
			Shared reserved instances and savings plans discounts across all accounts
			API is availabile to automate AWS account creation 
			Organization Units (OU)
				sales OU 
				finance OU
				prod OU
				dev OU etc 
			Security
				Service Control Policies(SCP)
					IAM policies applied to OU or Accounts to restrict users and Roles
					do not apply to Management account(Admin power) 
					Must have explicit allow 
					Block lists and allow lists strategies 
		IAM Conditions 
			aws:SourceIp
			aws:RequestedRegion
			ec2:ResourceTag
			aws:MultiFactorAuthPresent 
			aws:PrincipalOrgID
				to restrict access to accounts of AWS Organization
		IAM roles vs Resource Based Policies
			Cross Account
				attach resource based policy to resource
					u doesn't giveup any permissions 
					ex:user in Acc A needs to scan a DynamoDB in Acc A and write it in S3 bucket in Acc B  
					must use resource based policies 
				OR using IAM role as proxy 
					When u assume a role(user,app or service)
					u giveup ur original permissions and take permissions assigned to role
			Amazon EventBridge
				when a rule runs, it needs permissions on targets 
				Resource based policies
					SNS,SQS,CloudWatch Logs,API Gateway..
				IAM Role 
					Kinesis Streams, Systems Manager Run Command, ECS task..
		IAM Permission Boundaries 
			only for users and roles(not groups)
			to set max permissions an IAM entity get 
			In permission bourdary 
				if user is allowed full access to S3,EC2 
				if create user permission added through IAM policy to user 
				still user can't create users because of IAM Boundaries policies
		***Explicit Deny >>> Explicit Allow 
		AWS IAM Identity Center (successor to AWS Single Sign-On)
			One Login for all ur
				AWS accounts in AWS Organization
				Business cloud applications (salesforce,Box,Mircosoft 365)
				SAML2.0-enabled apps 
				EC2 Windows Instances
			Identity providers 
				Built-in identity store in IAM Identity Center 
				3rd party: Active Directory, OneLogin, Okta 
			Fine grained permissions and Assignments 
				Multi-Account permissions
					permission sets 
						a collection of one or more IAM policies assigned 
						to users and groups to define AWS access
				Application Assignments
					SSO access to many SAML2.0 Business apps 
					provide required URLs,certificates and metadata 
				Attribute-Based Access Control(ABAC)
					fine-grained permissions based on users attributes 
					stored in Identity Center Identity Store
					ex:cost center,title,locale 
					use case: define access once then Modify AWS access by changing attributes 
		Microsoft Active Directory
			found on any Windows Server with AD Domain services 
			Database of objects 
				user accs, computers, printers, file shares, security groups 
			centralized security management, create account, assign permissions 
			objects are organized in trees 
			group of trees is forest 
		AWS Directory Services 
			AWS Managed Microsoft AD 
				create ur own AD in AWS, manage users locally,supports MFA 
				Establish "Trust" connections with ur on-premise AD 
					login can check in AWS AD for user if user is not found in On-prem AD
					vice versa 
			AD Connector 
				Directory Gateway (proxy) to redirect to on-premise AD 
				supports MFA 
				users are managed on on-prem AD 
			Simple AD 
				AD-Compatible managed directory on AWS 
				Cannot be joined with on-premise AD 
			Active Directory setup	
				connect to an AWS Managed Mircosoft AD 
					can easily connect 
				Connect to Self-Managed Directory
					Create Two-Way Trust Relationship using AWS Managed Mircosoft AD
					OR
					Create an AD Connector (proxy)
		AWS Control Tower 
			easy way to setup and govern a secure and compliant multi-account AWS environment 
			based on best practices 
			Uses AWS Organizations to create accounts
			benifits
				Automate setup of environment in a few Clicks 
				Automate on going policy management using gaurdrails 
				Delete policy violation and remediate them 
				Monitor Compliance through interactive dashboards
			Guardrails 
				Preventive Gaurdrail
					using Service Control Policies(SCPs)
					ex:restrict regions across all ur accounts 
				Detective Guardrail 
					using AWS Config 
					ex:identify untagged resources 
				
	Security 
		Encryption
			In-flight (SSL)
				SSL certificate helps with encryption(HTTPS)
			Server-side encryption At-rest 
				AWS Key Management Service (KMS)
					Able to Audit KMS Key usage using CloudTrail
					available through API calls(SDK,CLI)
					Key Types 
						Symmetric(AES-256)
							Single encryption key used to encrypt and Decrypt
							AWS Services using KMS use Symmetric keys 
							u never get access to KMS key unencrypted
						Asymmetric(RSA & ECC key pairs)
							Public key (encrypt) and Private Key(decrypt) pair
							used for encrypt/decrypt or sign/verify operations 
							public key is downloadable, but can't access private key unencrypted
							Use case 
								encryption outside of AWS by users who can't call KMS API 
					KMS Key types 
						AWS Owned keys (free)
							SSE-S3,SSE-SQS,SSE-DDB etc (default)
						AWS Managed Keys (free)
							aws/service-name
							ex:aws/rds,aws/ebs
						Customer Managed keys 
							created in KMS 
							$1 per month
						Customer Managed Keys imported (must be Symmetric)
							$1 per month
						+ Pay for API call to KMS ($0.003/1000 calls)
					Automatic Key Rotation 
						AWS managed KMS key 
							automatic every year 
						Customer managed KMS key 
							must be enabled
							automatic every year
						imported KMS key 
							only manual rotation is possible using Alias 
					Copying Snapshot across regions 
						re-encrypt snapshot using new KMS key 
						restore snapshot with new KEY 
						same KMS key cannot live in two regions 
					KMS Key Policies
						similar to S3 bucket policies 
						Difference:u can't control access without them 
						Default
							created if u don't provide a policy 
							complete access to the key to root user 
						Custom KMS Key Policy 
							define users,roles that can access the Key
							define who can administer key 
							use case 
								cross acc access for KMS key 
							
					KMS Multi-region keys 
						has same key ID,key material, automatic rotation 
						No need to re-encrypt or making cross-Region API calls 
						are not global (primary+replicas)
						use case 
							global client side encryption
							encryption on Global DynamoDB, Global Aurora
					S3 replication 
						unencrypted objects and objects with SSE-S3 are replicated by default
						Objects with SSE-C(customer provided key) are never replicated 
						for objects with SSE-KMS 
							need to enable option 
							specify KMS key to encrypt target bucket 
							adapt KMS key policy for target key 
							IAM role with kms:Decrypt for source KMS key and kms:Encrypt for target KMS key 
							might get KMS throtling errors, can ask for Service Quotas increase 
							can use Multi-region keys but they treated as 
							independent keys (objects are still decrypted and then encrypted)
					AMI Sharing process Encrypted via KMS 
						In source acc, AMI is encrypted with KMS key 
						must modify image attribute to launch permission which responds 
						to target AWS account 
						Must share KMS key used to encrypt AMI with target acc 
						IAM role/user in target acc must have permissions to DescribeKey, ReEncrypted 
						CreateGrant,Decrypt 
						when launching EC2 instance from AMI, optionally the target acc 
						can specify new KMS key in it's own acc to re-encrypt the volumes 						
			Client-side encryption
		SSM Parameter store 
			secure storage for configuration and secrets 
			Optional seamless encryption using KMS 
			Serverless, scalable, durable, easy SDK 
			Version tracking of configurations/secrets
			Security through IAM 
			Notifications with EventBridge
			Integration with CloudFormation 
			keys are stored in Hierarchy 
			can reference secrets from Secrets Manager 			
			Standard
				no of parameters per acc 10,000
				max size of value 4KB 
				no parameter policies 
				no additional charges 
				free storage 
			Advanced 
				no of parameters per acc 100,000
				max size of value 8KB 
				parameter policies available
				additional charges 
				$0.05 per advanced parameter per month 
			Parameter policies(for advanced parameters)
				can assign TTL to a parameter (expiration date)
				to force updating or deleting sensitive data 
				can assign multiple policies 
				types 
					Expiration
					ExpirationNotification 
					NoChangeNotification
		AWS Secrets Manager 
			can store secrets 
			can force rotation of secrets every X days 
			Automatic generation of secrets on rotation (uses lambda)
			Integration with Amazon RDS (MySQL,PostgreSQL,Aurora) and other services 
			Secrets are encrypted using KMS 
			mostly used for RDS integration
			Multi-Region secrets 
				primary and replicas 
				can promote replica to standalone secret 
		AWS Certificate Manager (ACM)
			provision,manage and deploy TLS certificates(HTTPS/SSL)
			supports both public and private TLS certifiactes 
			free of charge for public certificates
			Automatic TLS certifiacte renewal 
			Integrations with 
				Elastic Load Balancer (CLB,ALB,NLB)
				CloudFront Distributions 
				APIs on API Gateway 
			Cannot use ACM with EC2
			Requesting Public certifiactes
				list domain names to included in certificate	
					fully qualified domain name 
						corp.example.com
					Wildcard domain 
						*.example.com 
				Validation method 
					DNS validation 
						preffered for automation perposes
						leverage CNAME record to DNS config 
					Email validation 
						will send emails to contact address in WHOIS database 
			Import public certificates
				can generate cert outside ACM and import it 
				no automatic renewal, must import new cert before expiry 
				ACM sends daily expiration events starting 45 days prior to expiration 
					no of days can be configured 
					events appear in EventBridge
				AWS Config has a managed Rule name acm-certificate-expiration-check 
				to check for expiring certificate 
		AWS Web Application Firewall (WAF)
			protects web application from common web expoits (Layer 7)
			Layer 7 is HTTP(vs Layer 4 TCP/UDP)
			Deploy 
				Application Load Balancer 
				API Gateway
				CloudFront
				AppSync GraphQL API 
				Cognito User pool 
			not possible for Network Load balancer(NLB) cause it is Layer 4
			Define Web Access Control List (ACLs)
				IP Set
					upto 10,000 IP Addresses
					use multiple rules for more IPs 
				HTTP headers,body or URI strings protects from common attack 
					SQL injection and cross-site Scripting (XSS)
			WAF is regional except for CloudFront
			rule group 
				reusable set of rules u can add to ACLs 
			Fixed IP while using WAF with Load Balancer
				WAF doesn't support Network Load balancer
				Global Accelerator for fixed IP and WAF on ALB 
		AWS Shield 
			protect from DDoS(Distributed denial of service) attack 
			Standard
				Free that is activated for every AWS customer 
				protects from SYN/UDP Floods,Reflection attacks,and other layer 3/4 attacks 
			Shield Advanced
				$3000 per month 
				protect against attack on Amazon EC2,ELB,CloudFront, AWS Global Accelerator and Route 53
				24/7 access to AWS DDoS response team (DRP)
				automatic application layer DDoS mitigation creates, evaluates and deploys 
				AWS WAF rules to mitigate layer 7 attacks 
		AWS Firewall Manager 
			manage rules across all accounts in AWS Organization
			Security Policy 
				common set of security rules 
				WAF rules (ALB,API gateway,CloudFront)
				AWS Shield Advanced(ALB,CLB,NLB,Elastic Ip,CloudFront)
				Security groups for EC2,ALB,ENI resources in VPC 
				AWS Network Firewall (VPC level)
				Amazon Route 53 Resolver DNS Firewall
				Policies are created a Regional level 
			Rules applied to new resources as they created 
		Amazon GaurdDuty 
			Intelligent threat discovery to protect ur AWS acc 
			uses Machine learning alogs, anomaly detection, 3rd party data 
			no need to install software
			input data 
				CloudTrail Event Logs 
					unusual API calls, unauthorized deployments
					CloudTrail Management Events 
					CloudTrail S3 Data Events 
				VPC Flow Logs 
					unusual internet traffic, unusual IP 
				DNS logs 
					compromised EC2 instances sending encoded data within DNS queries 
				Optional Features 
					EKS Audit logs,RDS,Aurora,EBS,Lambda,S3 data events 
			Can setup EventBridge rules to be notified in case of Findings
			Can protect against "CryptoCurrency attacks" (dedicated finding for it)
		Amazon Inspector 
			Automated Security Assessments 
			Only for EC2,Container Images,Lambda funtions
			For EC2 Instances 
				Leveraging AWS System Manager (SSM) agent 
				Analyze against unintended network accessibility 
			For Container images push to ECR 
			For Lambda functions
				identify software vulnerabilities in function code and dependencies 
			Reporting and integration with AWS Security Hub 
			Send findings to Amazon EventBridge
		Amazon Macie 
			fully managed data security and data privacy service
			uses ML and pattern matching to discover and protect ur sensitive data in AWS 
			helps identify and alert u to sensitive data, such as personally identifiable information (PII)
		Quiz 
			You have created a Customer-managed CMK in KMS that you use to encrypt both S3 buckets and EBS snapshots.
			Your company policy mandates that your encryption keys be rotated every 3 months. What should you do?
				Rotate the KMS CMK manually. Create a new KMS CMK and use Key Aliases to reference the new KMS CMK.
				Keep the old KMS CMK so you can decrypt the old data
			You have generated a public certificate using LetsEncrypt and uploaded it to the ACM so you can use and 
			attach to an Application Load Balancer that forwards traffic to EC2 instances.
			As this certificate is generated outside of AWS, it does not support the automatic renewal feature. 
			How would you be notified 30 days before this certificate expires so you can manually generate a new one?
				Configure EventBridge for Daily Expiration Events from ACM to invoke SNS notifications to your email
			
	Networking - VPC 
		Private IP 
			can only allow certain values 
			10.0.0.0/8 in big networks 
			172.16.0.0/12 aws default VPC in that range 
			192.168.0.0/16 home networks 
		All rest of the IP addresses on Internet are Public 
		Default VPC 
			all new AWS accounts have default VPC 
			New EC2 instances are launched into the default VPC if no subnet is specified 
			has internet connectivity and all EC2 instances inside it have public IPv4 addresses 
			also get public and private IPv4 DNS names 
		VPC 
			can have max 5 per region 
			Max CIDR per VPC is 5, each CIDR 
				min size is /28 (16 IPs)
				max size is /16 (65535 IPs)
			VPC is private so only private IPv4 ranges are allowed 
			VPC should not overlap with ur other networks
		Subnet IPv4 
			AWS reserves 5 IPs (first 4 and last 1) in each subnet 
			cannot use reserved IPs 
			ex:10.0.0.0/24 reserved IPs are 
				network address 10.0.0.0
				reserved by AWS for VPC router 10.0.0.1
				reserved by AWS for mapping to Amazon-provided DNS 10.0.0.1
				reserved by AWS for future use 10.0.0.1
				AWS doesn't not support broadcast in VPC so it is reserved 10.0.0.255
			if u need 29 IPs for EC2 instances 
				can't choose /27 (32 IPs,32-5=27<29)
				choose /26 (64 IPs,64-5=59>29)
		Internet Gateway (IGW)
			allows resources ex:EC2 in a VPC connect to internet 
			scales horizontally and is highly available and redundant 
			must be created separately from a VPC 
			1 VPC can only attached to 1 IGW and vice versa 
			*IGWs on their own do not allow Internet access 
			route tables must be edited 
		Bastion Hosts
			to SSH into our private EC2 instances 
			bastion is in public subnet which is then connected to all private subnets 
			Bastion Host security group must allow inbound from internet on port 22 
			from restricted CIDR (ex:public CIDR of ur corporation)
			Security group of EC2 instances must allow security group of private IP of Bastion Host 
		NAT Instance 
			NAT - Network Address Translation 
			allows EC2 Instances in private subnet to connect to Internet 
			Must be launched in public subnet 
			Must disable EC2 setting Source/destination check 
			Must have Elastic IP attached to it 
			Route Tables must be configured to route traffic from private subnets to NAT instance 
			Pre-configured Amazon Linux AMI availbale 
				reached end of standard support on 2020 
			Not Highly available 
			internet bandwidth depends on EC2 instance type 
			must manage security groups & rules 
				inbound 
					allow http/https traffic coming from private subnet 
					all ssh from home networks 
				outbound 
					allow http/https traffic to internet 
		NAT Gateway 
			AWS-managed NAT, high-bandwidth, high availability, no administration 
			pay per hour usage and bandwidth
			NATGW is created in specific AZ, uses Elastic IP 
			can't be used by EC2 Instance in same subnet (only from other subnet)
			Require Internet Gateway (private subnet=>NATGW=>IGW)
			5Gbps of bandwidth with autoscaling upto 100Gbps 
			no security groups to manage/required
			resilient within single AZ 
			must create multiple NAT gateways in multiple AZs for fault-tolerance 
			there is no cross-AZ failover needed because if AZ goes down it doesn't need NAT 
		Network Access Control List (NACL)
			stateless
			request is evaluated at NACL before going to security groups 
			if request is comming from EC2, request is evaluated at security groups then NACL 
			firewall which control traffic from and to 	subnets 
			One NACL per subnet, new subnets are assigned the default NACL 
			NACL Rule 
				have number(1-32766),high precedence with low number 
				last rule is an asterisk(*) and denies a request if no rule match 
			newly created NACL will deny everything 
			NACL are create way of blocking a specific IP address at subnet level 
			Default NACL 
				Accepts everything inbound/outbound with subnets it's associated with 
			Ephemeral Ports 
				for any two endpoints to connect, they must use ports 
				Clients connect to defined port and expect a response on an Ephemeral port 
			NACL with Ephemeral ports 
			Security Groups vs NACLs 
				Security Groups
					instance level 
					allow rules only 
					stateful 
					all rules are evaluated 
					applies to instance when specified by someone
				NACL 
					subnet level 
					support both allow and deny rules 
					stateless
					rule are evaluated in order (low to hight priority no), first match wins 
					automatically applies to all EC2 Instances in subnet that its associated with 
		VPC Peering 
			privately connect two VPCs using AWS Network
			must not have overlapping CIDRs
			not transitive 
			must update route tables in each VPC subnets to ensure EC2 instances can communicate 
			within or across AWS accounts/region 
			can reference a security group in a peered VPC (works across accounts - same region)
		VPC Endpoints (AWS PrivateLink)
			every AWS service is publically exposed (public url)
			VPC endpoints (powered by AWS PrivateLink) allow u to connect AWS services using a private network
			instead of public internet
			redundant and scale horizontally 
			removes the need of IGW,NATGW,... to access AWS Services 
			In case of Issues 
				check DNS setting resolution in ur VPC 
				Check route tables 
			Types 
				Interface Endpoints 
					powered by PrivateLink
					provisions an ENI (private IP) as an entry point 
					must attach a security group
					supports most AWS services 
					$ per hour + $ per GB of data processed 
					preffered if access is required from on-premise (Site-Site VPN or Direct Connect)
					a different VPC or different region
				Gateway Endpoints 
					provisions a gateway and must be used as target in route table 
					doesn't use security groups 
					supports both S3 and DynamoDB
					Free
		VPC Flow Logs 
			capture information about IP traffic going into ur interfaces 
				VPC flow Logs
				subnet flow logs 
				Elastic Network Interface (ENI) flow logs 
			more & troubleshoot connectivity issues 
			logs can go to S3, CloudWatch logs,and Kinesis Data firehose
			captures network info from AWS managed interfaces too
				ELS,RDS,ElastiCache,Redshift,workspaces,NATGW,Transit Gateway

		AWS Site-to-Site VPN 
			Virtual Private Gateway(VGW)
				VPN concentrator on the AWS side of VPN connection 
				VGW is created and attached to VPC from which u want to create site-to-side VPN 
				can customize ASN (Autonomous System Number)
			Customer Gateway
				software app or physical device on customer side of VPN connection 
			Customer Gateway Device(on-prem)
				what IP to use 
					public internet-routable Ip for ur customer gateway device 
					if it's behind a NAT device that's enabled for NAT traversal (NAT-T) use
					public ip of NAT device 
			Enable route propagation for virtual private gateway in route table that is associated with ur subnets 
			if needed to ping ur EC2 from on-prem, make sure to add ICMP protocol on inbound of security group 
		AWS VPN CloudHub 
			provide secure communication between multiple sites, if u have multiple VPN connections 
			low-cost hub-and-spoke mode for primary or secondary network connectivity between different locations
			to set it up,connect multiple VPN connections on same VGW, setup dynamic routing and configure route tables 
		
		Direct Connect 
			provides dedicated private connection from a remote network to ur VPC 
			dedicated connection must be setup between ur DC and AWD Direct Connect Location 
			need to setup Virtual Private Gateway in ur VPC 
			access public resources and private (EC2) on same connection
			use case 
				increase bandwidth throughput 
				more consistent network experience
				Hybrid Environments (on-prem + cloud)
			supports both IPv4 and IPv6 
			Direct Connect Gateway
				if u want to setup direct connect to one or more VPC in many different regions (same account)
				must use Direct Connect Gateway 
			Connection Types 
				Dedicated Connections 
					1Gbps,10Gbps and 100 Gbps capacity 
					physical ethernet port dedicated to a customer 
					request made to AWS first the completed by AWS Direct Connect Partners 
				Hosted Connection
					50Mbps,500Mbps to 10Gbps 
					connection requests are made via AWS Direct Connect Partners
					capacity is added or removed on demand 
					1,2,5,10 Gbps availabile at select AWS Direct Connect Partners
				Lead times are after longer than 1 month to establish new connection 
			Encryption 
				Data in transit is not encrypted but private 
				AWS Direct Connect + VPN provide IPsec-encrypted private connection 
			Resiliency 
				high Resiliency
					one connection for multiple locations (one connection in each location)
				max Resiliency 
					separate connections terminating on separate devices in more than one location 
					multiple location each having separate connections on separate devices 
		Site-to-Site VPN as backup for Direct Connect, vice versa 

		Transit Gateway 
			for transitive peering between thousands of VPC and on-prem, hub-and-spoke(star) connection 
			regional resource, can work cross region 
			can share to cross-account using resource access manager (RAM)
			can peer transit gateways across regions 
			route tables 
				limit which VPCs can talk to other VPCs 
			works with Direct Connect Gateway and VPN connections 
			*supports IP multicast (not supported by any other AWS service)
			Site-to-Site VPN ECMP 
				equal cost multi path(ECMP) routing
				to allow forward a packet over multiple best path 
				use case 
					create multiple Site-to-Site VPN connections to increase bandwidth of ur connection with AWS 
			can share Direct Connect to multiple accounts 
		VPC Traffic Mirroring 
			to capture and inspect network traffic in ur VPC 
			route the traffic to security appliances u manage 
			capture traffic 
				from - ENIs 
				to - ENI or Network Load Balancer 
			capture all packet or of ur interest 
			source and target can be in same or different VPC (VPC Peering)
			use cases 
				content inspection, threat monitoring 
				troubleshooting
		IPv6 for VPC 
			provides 3.4x10^38 unique IPs 
			every IP is public and Internet-routable (no private range)
			IPv4 cannot be disabled for ur VPC 
		Egress only Internet Gateway
			used for IPv6 only
			similar to NAT Gateway but for IPv6 
			must update route tables 
		Classic Link 
			connect EC2-Classic EC2 instances privately to ur VPC 
		for EC2 Use private IP instead of public IP for good savings and better network performance
		AWS Network Firewall
			protect entire VPC
			from layer 3 to layer 7 protection 
			any direction, u can inspect 
				VPC to VPC 
				outbound to internet 
				inbound from internet 
				to/from Direct Connect & Site-to-Site VPN 
			internally it uses AWS Gateway Load Balancer 
			rules can be centrally managed cross-account by AWS Firewall Manager to apply to many VPCs
			supports 1000s of rules 
				IP & Port 
				protocol 
				stateful domain list groups 
				general pattern matching using regex 
			Traffic Filtering 
				allow,drop or alert for the traffic that matches the rules 
			Active flow inspection to protect network threats with intrusion-prevention capabilities 
		Quiz 	
			You have attached an Internet Gateway to your VPC, but your EC2 instances still 
			don't have access to the internet. What is NOT a possible issue?
				The Security Group does not allow traffic in
				Security groups are stateful and if traffic can go out, then it can go back in.
			How can you capture information about IP traffic inside your VPCs?
				Enable VPC Flow Logs 
			A web application hosted on a fleet of EC2 instances managed by an Auto Scaling Group.
			You are exposing this application through an Application Load Balancer. 
			Both the EC2 instances and the ALB are deployed on a VPC with the following CIDR 192.168.0.0/18.
			How do you configure the EC2 instances' security group to ensure only the ALB can access them on port 80
				Add an Inbound rule with port 80 and ALB security group as source 
				Referencing by security groups in rules is an extremely powerful rule
	
	Disaster Recovery 
		RPO (Recovery Point objective)
		RTO (Recovery Time objective)
		Strategies
			Backup & Restore 
				High RPO
				High RTO 
			Pilot Light 
				small version of app is always running 
				useful for critical core 
				low RTO 
				low RPO 
			Warm Standby 
				full system is up and running, but at minimum size 
			Multi Site/Hot Site 
				Very low RTO (minutes or seconds)
				very expensive 
				full production scale is running AWS and On-premise 
		Backup 
			EBS Snapshots, RDS automated backups/Snapshots 
			Regular pushes to S3/S3 IA/Glacier, Life cycle policy, cross region replication
			from on-premise:Snowball or Storage Gateway 
		High Availability
			Use Route 53 to migrate DNS over from Region to Region 
			RDS Multi-AZ, ElastiCache Multi-AZ, EFS S3 
			Site-to-Site VPN as a recovery for Direct Connect 
		Replication 
			RDS Replication(Cross Region),AWS Aurora + Global databases
			Data replication from on-prem to RDS 
			Storage Gateway 
		Automation 
			CloudFormation/Elastic Beanstalk to recreate a wholenew environment
			Recover/Reboot EC2 instances with CloudWatch if alarm fails 
			AWS lambda functions for customised automations 
		Chaos 
			Netflix has simian-army randomly terminating EC2 
	Migrations 
		Database Migration Service (DMS)
			quickly and securely migrate databases to AWS, resilient, self healing
			source database remains availabile during migration 
			supports 
				Homogeneous migrations 
					oracle to oracle etc 
				Heterogeneous migrations
					Microsoft SQL Server to Aurora
			Continuous Data Replication using CDC (Change Data Capture) 
			must create EC2 instance to perform replication tasks 
			AWS Schema Conversion Tool (SCT)
				convert ur database schema from one engine to another 
				no need to use SCT if u are migrating the same DB engine 
			Multi-AZ Deployment
				DMS provisions and maintains a synchronously stand replica in a different AZ 
				Advantages 
					provides data redundency 
					Eliminates I/O freezes
					Minimum latency spikes 
		RDS & Aurora MySQL Migrations 
			RDS MySQL to Aurora 
				take RDS MySQL snapshot and restore as MySQL Aurora DB 
				Or 
				create Aurora Read replica from RDS MySQL 
				when it's completed promote it as it's own DB cluster 
				this takes time and cost 
			External MySQL to Aurora MySQL
				use Percona XtraBackup utility to create a file backup in Amazon S3 
				Create Aurora MySQL DB from Amazon S3 
				Or 
				create Aurora MySQL DB 
				use mysqldump utility to migrate MySQL into Aurora 
				slower than S3 method
			Use DMS if both databases are up and running
		RDS & Aurora PostgreSQL Migrations 
			RDS PostgreSQL to Aurora PostgreSQL
				take RDS PostgreSQL snapshot and restore as PostgreSQL Aurora DB 
				Or 
				create Aurora Read replica from RDS PostgreSQL 
				when it's completed promote it as it's own DB cluster 
				this takes time and cost 
			External PostgreSQL to Aurora PostgreSQL
				create a backup and put it in Amazon S3 
				Import it using aws_s3 Aurora extension
			Use DMS if both databases are up and running
		
		On-premise strategy with AWS 
			can download Amazon Linux 2 AMI as a VM(.iso format)
				use it in VMWare,VirtualBox, Microsoft Hyper-V 
			VM Import/Export
				Migrate existing apps to EC2 
				create DR repository strategy for on-premise VMs 
				Can export back VMs from EC2 to on-premise 
			AWS Application Discovery Service 
				Gather info about ur on-premise servers to plan a migration 
				server untilization and dependency mappings 
				Track with AWS Migration Hub 
			AWS Database Migration Service (DMS)
				replicate on-prem=>AWS, AWS=>AWS, AWS=>on-prem 
			AWS Server Migration Service (SMS)
				Incremental replication of on-premise live servers to AWS 
		AWS Backup 
			fully managed service 
			centrally manage and automate backups across AWS Services
			supported services 
				EC2/EBS 
				S3
				RDS/Aurora/DynamoDB
				DocumentDB/Neptune 
				EFS/FSx(Lustre & Windows File System)
				Storage Gateway(volume gateway)
			supports cross-region backups 
			supports cross-account backups 
			supports PITR(point-in-time recovery) for supported services 
			On-demand and Scheduled Backups 
			Tag-based backup policies
			create backup policies known as Backup Plans 
			Backup Plans
				Backup frequency 
				Backup window 
				Transition to Cold Storage 
				Retention Period 
			Backup Vault Lock 
				Enforce WORM (Write Once Read Many) state for all backups u store in Vault 
				even root user cannot delete backups when enabled 
		AWS Application Discovery Service 
			Plan migration projects by gathering info about on-premise data centers 
			Server uitlization data and dependency mapping are important for migrations 
			Agentless Discovery (AWS Agentless Discovery Connector)
				VM inventory, configuration and performance history such as CPU,memory and disk usage 
			Agent based Discovery (AWS Application Discovery Agent)
				System configuration,system performance,running processes, and details of network connections between systems 
			Resulting Data can be viewed within AWS Migration Hub 
		AWS Application Migration Service (MGN)
			Lift and shift 
			converts ur physical virtual and cloud based servers to run natively in AWS 
			Supports wide range of platforms,OS and databases 
			Minimum downtime,reduced costs 
		VMWare cloud on AWS 
			extend on-prem VMWare cloud to AWS 
			use case 
				migrate VMWare vSphere workloads to AWS 
				run workloads across VMWare vSphere-based private, public and hybrid cloud Environments
				have a disaster recovery strategy 
		Quiz 
			AWS DataSync supports the following locations, EXCEPT
				Amazon EBS 
	Solution Architectures
		Compute and Networking
			EC2 Enhanced Networking(SR-IOV)
				higher bandwidth, higher PPS (packet per sec),low latency 
				option1: Elastic Network Adapter(ENA) upto 100Gbps
				option2: Intel 82599 VF upto 10Gbps - Legacy 
			Elastic Fabric Adapter (EFA)
				Improved ENA for High Performance Computing(HPC) 
				only works for Linux 
				great for inter-node communications,tightly coupled workloads
				Leverages Message Passing Interface(MPI) standard
				Bypasses underlying Linux OS to provide low-latency,reliable transport 
		Automation and Orchestration 
			AWS Batch 
				supports multi-node parallel jobs, which enables u to run single jobs that span multiple EC2 instances 
				easily schedule jobs and launch EC2 intances 
			AWS ParallelCluster 
				open-source cluster management to deploy HPC on AWS 
				configure with TEXT files 
				Automate creation of VPC,subnet, cluster type and instance types 
				can enable Elastic Fabric Adapter (EFA) on cluster for improved network performance
			Quiz 
				You are working on a Serverless application where you want to process objects uploaded to an S3 bucket. 
				You have configured S3 Events on your S3 bucket to invoke a Lambda function every time an object has 
				been uploaded. You want to ensure that events that can't be processed are sent to a Dead Letter Queue (DLQ) 
				for further processing. Which AWS service should you use to set up the DLQ?
					Lambda function
	Other Services 
		CloudFormation
			declarative way of outlining ur AWS infrastructure
			Infrastructure as code 
			Cost 
				East resources within stack is tagged with an identifier so can easily see how much a stack costs 
				can estimate cost of resources using CloudFormation Template 
				Savings strategy 
					can automate deletion of Templates at any time and recreate at specific time u want 
			Productivity 
				automatic generation of Diagram for ur templates 
			Don't re-invent the wheel 
				leverage existing templates on web 
				leverage Documentation 
			CloudFormation Stack Designer 
				graphical view of stack resources and their relations   

		Amazon Simple Email Service (SES)
			send emails globally at scale 
			allow inbound/outbound emails 
			dashboard, performance insights, anti-spam feedback 
			supports DoaminKeys identified Mail (DKIM) and Sender Policy framework(SPF)
			Flexible IP deployment: shared, dedicated and customer owned IPs
			send emails using ur apps 
				AWS Console 
				APIs
				SMTP 
		Amazon Pinpoint 
			Scalable 2 way (outbound/inbound) marketing communication service 
			support email,SMS,push,voice and in-app messaging 
			can segment and personalize messages with right content to customers 
			Use case 
				run campiagns by sending marketing bulk transactional SMS messages 
			vs Amazon SNS and Amazon SES 
				In SNS and SES, u manage each message's audience, content and delivery schedule 
				In Pinpoint, u create message templates,delivery schedules, highly-targeted segments and full campaigns 
		Systems Manager 
			SSM Session Manager 
				allows to start a secure shell on ur EC2 and on-premise servers 
				No SSH access,bastion hosts or SSH keys needed 
				No port 22 needed (better security)
				supports Linux,MacOS and windows 
				Send session log data to S3 or CloudWatch Logs 
			Run Command 
				execute a script or a command 
				run command across multiple instances 
				No need for SSH 
				send notifications to SNS about command status 
				can be invoked using EventBridge
			Patch Manager 
				Automate patching managed instances 
				OS updates, applications updates, security updates 
				Supports EC2 and on-premise servers
				support linux,macos,windows 
				Path on-demand or on a schedule using Maintenance Windows
				Scan instances and generate patch compliance report 
			Maintenance Windows 
				Schedule when to perform operation on instances 
				schedule,duration,set of registered instances and set of registered tasks 
			Automation 
				simplifies common maintenance  and deployment tasks of EC2 instances and other AWS resources
				ex:restart instances, create AMI,EBS snapshots 
				Automation Runbook 
					SSM documents to define actions performed on EC2 instances or AWS resources 
				Can be triggered using 
					manual 
						Console,CLI or SDK 
					EventBridge
					Maintenance Windows 
					AWS Config for rules remediations 
		Cost Explorer 
			Visualize,understand and manage ur AWS costs and usage overtime 
			create custom reports 
			cost saving plan 
			Forecast usage 
		Amazon Elastic Transcoder 
			convert media files in S3 into media files in formats required by consumer playback devices 
		AWS Batch 
			batch processing at any scale 
			dynamically launch EC2 instances or Spot Instances 
			provisions right amount of compute/memory
			submit or schedule batch jobs 
			defined as Docker images and run on ECS
		Amazon AppFlow 
			securely transfer data between SaaS apps and AWS 
			Source 
				salesforce,SAP,Zendesk,Slack and ServiceNow 
			Destinations 	
				S3,Redshift or non-AWS such as SnowFlake and salesforce
			frequency
				on schedule,in response to events or on-demand 
			Data transformations
				filtering and validation 
			Encrypted 
				over public internet or privately over AWS PrivateLink 
		AWS Amplify 
			set of tools and services that helps u develop and deploy scalable full stack web and mobile apps
			Authentication, Storage, API, CI/CD, PubSub, Analytics, AI/ML Predictions, Monitoring
			Connect source code from GitHub,AWS CodeCommit,BitBucket,GitLab or upload Directly 
	
	Trusted Advisor 
		provide recommendations on 5 categories 
			Cost optimization 
			Performance
			Security
			Fault Tolerance 
			Service Limits 
		Support Plans
			Basic & Developer Support Plan 
				S3 Bucket Permissions 
				Security Groups 
				IAM use 
				MFA on root account 
				EBS public snapshots 
				RDS public snapshots 
				Service limits 
			Business & Enterprise Support Plan 
				full checks available on 5 categories 
				can set CloudWatch alarms when reaching limits 
				Programatic access using AWS support API 