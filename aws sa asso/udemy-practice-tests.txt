Quiz 
    A retail company uses AWS Cloud to manage its technology infrastructure. 
    The company has deployed its consumer-focused web application on EC2-based web servers and uses 
    RDS PostgreSQL DB as the data store. The PostgreSQL DB is set up in a private subnet that allows inbound 
    traffic from selected EC2 instances. The DB also uses AWS KMS for encrypting data at rest.
    Which of the following steps would you recommend to facilitate secure access to the database?
        Configure RDS to use SSL for data in transit 

    Your company is deploying a website running on Elastic Beanstalk. The website takes 
    over 45 minutes for the installation and contains both static as well as dynamic files that must 
    be generated during the installation process.As a Solutions Architect, you would like to bring the 
    time to create a new instance in your Elastic Beanstalk deployment to be less than 2 minutes. 
    Which of the following options should be combined to build a solution for this requirement?
        Create a Golden AMI with the static installation components already setup
        Use EC2 user data to customize the dynamic installation parts at boot time

    A financial services company is looking to move its on-premises IT infrastructure to AWS Cloud. 
    The company has multiple long-term server bound licenses across the application stack and the CTO wants 
    to continue to utilize those licenses while moving to AWS.As a solutions architect, 
    which of the following would you recommend as the MOST cost-effective solution?
        EC2 dedicated Hosts 
    
    A pharma company is working on developing a vaccine for the COVID-19 virus. 
    The researchers at the company want to process the reference healthcare data in a 
    highly available as well as HIPAA compliant in-memory database that supports SQL query caching.
    As a solutions architect, which of the following AWS services would you recommend for this task?
        ElastiCache for Redis/Memcached(have query caching for SQL and NoSQl, ease load off ur databases)
    
    A media company has its corporate headquarters in Los Angeles with an on-premises data center 
    using an AWS Direct Connect connection to the AWS VPC. The branch offices in San Francisco and Miami 
    use Site-to-Site VPN connections to connect to the AWS VPC. The company is looking for a solution to
    have the branch offices send and receive data with each other as well as with their corporate headquarters.
    As a solutions architect, which of the following AWS services would you recommend addressing this use-case?
        VPN CloudHub 
        Sites that use AWS Direct Connect connections to the virtual private gateway can 
        also be part of the AWS VPN CloudHub. The VPN CloudHub operates on a simple hub-and-spoke model 
        that you can use with or without a VPC. 
    
    A financial services company recently launched an initiative to improve the security of its 
    AWS resources and it had enabled AWS Shield Advanced across multiple AWS accounts owned by the company. 
    Upon analysis, the company has found that the costs incurred are much higher than expected.
    Which of the following would you attribute as the underlying reason for the unexpectedly 
    high costs for AWS Shield Advanced service?
        Consolidated billing has not been enabled. All the AWS accounts should fall under a 
        single consolidated billing for the monthly fee to be charged only once
        no need to pay for every acc, pay only once in Consolidated billing
    
    A media agency stores its "re-creatable" assets on Amazon S3 buckets. The assets are accessed by a 
    large number of users for the first few days and the frequency of access falls down drastically 
    after a week. Although the assets would be accessed occasionally after the first week, but they 
    must continue to be immediately accessible when required. The cost of maintaining all 
    the assets on S3 storage is turning out to be very expensive and the agency is looking at 
    reducing costs as much as possible.As a Solutions Architect, can you suggest a way to lower the 
    storage costs while fulfilling the business requirements?
        Configure a lifecycle policy to transition the objects to Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)
        after 30 days
        *must store objects min 30 days before we transition it to other classes 
    
    The engineering team at an e-commerce company has been tasked with migrating to a serverless architecture. 
    The team wants to focus on the key points of consideration when using Lambda as a backbone for this 
    architecture.As a Solutions Architect, which of the following options would you identify as correct 
    for the given requirement?
        By default, Lambda functions always operate from an AWS-owned VPC and hence have access to 
        any public internet address or public AWS APIs. Once a Lambda function is VPC-enabled, 
        it will need a route through a NAT gateway in a public subnet to access public resources 
        If you intend to reuse code in more than one Lambda function, you should consider creating a 
        "Lambda Layer" for the reusable code
            You can configure your Lambda function to pull in additional code and content in the form of layers. 
            A layer is a ZIP archive that contains libraries, a custom runtime, or other dependencies. 
            With layers, you can use libraries in your function without needing to include 
            them in your deployment package. Layers let you keep your deployment package small, 
            which makes development easier. A function can use up to 5 layers at a time.
        Since Lambda functions can scale extremely quickly, its a good idea to deploy a CloudWatch Alarm 
        that notifies your team when function metrics such as ConcurrentExecutions or Invocations exceeds 
        the expected threshold
    
    A medium-sized business has a taxi dispatch application deployed on an EC2 instance. Because of an 
    unknown bug, the application causes the instance to freeze regularly. Then, the instance has 
    to be manually restarted via the AWS management console.Which of the following is the MOST cost-optimal 
    and resource-efficient way to implement an automated solution until a permanent fix is 
    delivered by the development team?
        Setup a CloudWatch alarm to monitor the health status of the instance. In case of an Instance Health 
        Check failure, an EC2 Reboot CloudWatch Alarm Action can be used to reboot the instance    
        Using Amazon CloudWatch alarm actions, you can create alarms that automatically stop,
        terminate, reboot, or recover your EC2 instances. 
    
    A company has noticed that its application performance has deteriorated after a new Auto Scaling 
    group was deployed a few days back. Upon investigation, the team found out that the Launch 
    Configuration selected for the Auto Scaling group is using the incorrect instance type that is 
    not optimized to handle the application workflow.As a solutions architect, what would you recommend 
    to provide a long term resolution for this issue?
        Create a new launch configuration to use the correct instance type. Modify the Auto Scaling group
        to use this new launch configuration. Delete the old launch configuration as it is no longer needed
        since it is not possible to modify a launch configuration once it is created
    
    A retail company wants to rollout and test a blue-green deployment for its global application in 
    the next 48 hours. Most of the customers use mobile phones which are prone to DNS caching. 
    The company has only two days left for the annual Thanksgiving sale to commence.As a Solutions 
    Architect, which of the following options would you recommend to test the deployment on as 
    many users as possible in the given time frame?
        Use AWS Global Accelerator to distribute a portion of traffic to a particular deployment
            AWS Global Accelerator uses endpoint weights to determine the proportion of 
            traffic that is directed to endpoints in an endpoint group
            since mobile phones which are prone to DNS caching, can't use Route 53
    
    A leading online gaming company is migrating its flagship application to AWS Cloud for delivering 
    its online games to users across the world. The company would like to use a Network Load Balancer (NLB)
    to handle millions of requests per second. The engineering team has provisioned multiple instances 
    in a public subnet and specified these instance IDs as the targets for the NLB.
    As a solutions architect, can you help the engineering team understand the correct routing 
    mechanism for these target instances?
        Traffic is routed to instances using the primary private IP address specified in the primary network 
        interface for the instance
            If you specify targets using an instance ID, traffic is routed to instances using the primary 
            private IP address specified in the primary network interface for the instance. 
            The load balancer rewrites the destination IP address from the data packet before 
            forwarding it to the target instance.
    
    A company manages a multi-tier social media application that runs on EC2 instances behind an Application 
    Load Balancer. The instances run in an EC2 Auto Scaling group across multiple Availability Zones and 
    use an Amazon Aurora database. As a solutions architect, you have been tasked to make the application 
    more resilient to periodic spikes in request rates. 
        Use Aurora Replica
        Use CloudFront distribution in front of the Application Load Balancer
    
    A retail company uses AWS Cloud to manage its IT infrastructure. The company has set up "AWS Organizations"
    to manage several departments running their AWS accounts and using resources such as EC2 instances and 
    RDS databases. The company wants to provide shared and centrally-managed VPCs to all departments 
    using applications that need a high degree of interconnectivity.As a solutions architect, 
    which of the following options would you choose to facilitate this use-case?
        Use VPC sharing to share one or more subnets with other AWS accounts belonging to the same parent 
        organization from AWS Organizations
            To set this up, the account that owns the VPC (owner) shares one or more subnets with 
            other accounts (participants) that belong to the same organization from AWS Organizations. 
            After a subnet is shared, the participants can view, create, modify, and delete 
            their application resources in the subnets shared with them. 

    The DevOps team at an IT company is provisioning a two-tier application in a VPC with a public 
    subnet and a private subnet. The team wants to use either a NAT instance or a NAT gateway in 
    the public subnet to enable instances in the private subnet to initiate outbound IPv4 traffic to 
    the internet but needs some technical assistance in terms of the configuration options available for 
    the NAT instance and the NAT gateway.
        NAT instance can be used as a bastion server
        Security Groups can be associated with a NAT instance
        NAT instance supports port forwarding
    
    An Electronic Design Automation (EDA) application produces massive volumes of data that can be 
    divided into two categories. The 'hot data' needs to be both processed and stored quickly in a parallel 
    and distributed fashion. The 'cold data' needs to be kept for reference with quick access for 
    reads and updates at a low cost.Which of the following AWS services is BEST suited to accelerate 
    the aforementioned chip design process?
        Amazon FSx for Lustre
            FSx for Lustre provides the ability to both process the 'hot data' in a parallel and distributed fashion 
            as well as easily store the 'cold data' on Amazon S3.
    
    A leading social media analytics company is contemplating moving its dockerized application 
    stack into AWS Cloud. The company is not sure about the pricing for using Elastic Container Service (ECS) 
    with the EC2 launch type compared to the Elastic Container Service (ECS) with the Fargate launch type.Which 
    of the following is correct regarding the pricing for these two services?
        ECS with EC2 launch type is charged based on EC2 instances and EBS volumes used. 
        ECS with Fargate launch type is charged based on vCPU and memory resources that 
        the containerized application requests
    
    An e-commerce company has copied 1 PB of data from its on-premises data center to an Amazon S3 bucket 
    in the us-west-1 Region using an AWS Direct Connect link. The company now wants to copy the data to 
    another S3 bucket in the us-east-1 Region. The on-premises data center does not allow the use of AWS Snowball.
        Copy data from the source bucket to the destination bucket using the "aws S3 sync" command
        Set up S3 batch replication to copy objects across S3 buckets in different Regions using S3 console
    
    An organization wants to delegate access to a set of users from the development environment so that 
    they can access some resources in the production environment which is managed under another AWS account.As a 
    solutions architect, which of the following steps would you recommend?
        Create a new IAM role with the required permissions to access the resources in the production environment. 
        The users can then assume this IAM role while accessing the resources from the production environment
    
    A junior scientist working with the Deep Space Research Laboratory at NASA is trying to upload a high-resolution 
    image of a nebula into Amazon S3. The image size is approximately 3GB. The junior scientist is using 
    S3 Transfer Acceleration (S3TA) for faster image upload. It turns out that S3TA did not result in 
    an accelerated transfer.Given this scenario, which of the following is correct regarding the charges for 
    this image transfer?
        The junior scientist does not need to pay any transfer charges for the image upload
            with S3TA, u pay only for transfers that are accelerated 
    
    While consolidating logs for the weekly reporting, a development team at an e-commerce company noticed that an 
    unusually large number of illegal AWS API queries were made sometime during the week. Due to the off-season, 
    there was no visible impact on the systems. However, this event led the management team to seek an automated 
    solution that can trigger near-real-time warnings in case such an event recurs.Which of the following 
    represents the best solution for the given scenario?
        Create an Amazon CloudWatch metric filter that processes CloudTrail logs having API call details and 
        looks at any errors by factoring in all the error codes that need to be tracked. Create an alarm based 
        on this metric's rate to send an SNS notification to the required team
    
    A retail company's dynamic website is hosted using on-premises servers in its data center in the United States.
    The company is launching its website in Asia, and it wants to optimize the website loading times for 
    new users in Asia. The website's backend must remain in the United States. The website is being launched 
    in a few days, and an immediate solution is needed.What would you recommend?
        Use Amazon CloudFront with a custom origin pointing to the on-premises servers
    
    A leading video streaming service delivers billions of hours of content from Amazon S3 to customers 
    around the world. Amazon S3 also serves as the data lake for its big data analytics solution. 
    The data lake has a staging zone where intermediary query results are kept only for 24 hours. 
    These results are also heavily referenced by other parts of the analytics pipeline.Which of the 
    following is the MOST cost-effective strategy for storing this intermediary query data?
        Store the intermediary query results in S3 Standard storage class
            S3 Glacier Instant Retrieval storage class
                The minimum storage duration charge is 90 days, so this option is NOT cost-effective 
                because intermediary query results need to be kept only for 24 hours. 

    A major bank is using SQS to migrate several core banking applications to the cloud to ensure 
    high availability and cost efficiency while simplifying administrative complexity and overhead. 
    The development team at the bank expects a peak rate of about 1000 messages per second to 
    be processed via SQS. It is important that the messages are processed in order.Which of the following
    options can be used to implement this system?
        Use Amazon SQS FIFO queue in batch mode of 4 messages per operation to process the messages at the peak rate
            FIFO queues support up to 300 messages per second (300 send, receive, or delete operations per second). 
            When you batch 10 messages per operation (maximum), FIFO queues can support up to 3,000 messages per second.
            Therefore you need to process 4 messages per operation so that the FIFO queue can support up to 1200 
            messages per second, which is well within the peak rate.
        
    A financial services company uses Amazon GuardDuty for analyzing its AWS account metadata to meet 
    the compliance guidelines. However, the company has now decided to stop using GuardDuty service. 
    All the existing findings have to be deleted and cannot persist anywhere on AWS Cloud.Which of the 
    following techniques will help the company meet this requirement?
        Disable the service in the general settings
            Disabling the service will delete all remaining data, including your findings and configurations
            before relinquishing the service permissions and resetting the service.
        
    A new DevOps engineer has joined a large financial services company recently. As part of his onboarding,
    the IT department is conducting a review of the checklist for tasks related to AWS Identity and Access Management.
        Enable MFA for privileged users
        Configure AWS CloudTrail to record all account activity
    
    A software engineering intern at an e-commerce company is documenting the process flow to provision 
    EC2 instances via the Amazon EC2 API. These instances are to be used for an internal application 
    that processes HR payroll data. He wants to highlight those volume types that cannot be used as a boot volume.
    Can you help the intern by identifying those storage volume types that CANNOT be used as 
    boot volumes while creating the instances? 
        Cold HDD (sc1)
        Throughput Optimized HDD (st1) 
            large streaming workloads where throughput (measured in MiB/s) is a better performance measure than IOPS.
            Throughput Optimized HDD (st1) and Cold HDD (sc1) volume types CANNOT be used as a boot volume
            General Purpose SSD (gp2), Provisioned IOPS SSD (io1), and Instance Store can be used as a boot volume.

    A video analytics organization has been acquired by a leading media company. The analytics organization 
    has 10 independent applications with an on-premises data footprint of about 70TB for each application. 
    The CTO of the media company has set a timeline of two weeks to carry out the data migration from 
    on-premises data center to AWS Cloud and establish connectivity.Which of the following are the 
    MOST cost-effective options for completing the data transfer and establishing connectivity?
        Order 10 Snowball Edge Storage Optimized devices to complete the one-time data transfer
            each provides upto 80TB of usable HDD 
            Each Snowmobile has a total capacity of up to 100 petabytes. To migrate 
            large datasets of 10PB or more in a single location, you should use Snowmobile.
        Setup Site-to-Site VPN to establish on-going connectivity between the on-premises data center and AWS Cloud
            Direct Connect involves significant monetary investment and takes at least a month to set up, therefore 
            it's not the correct fit for this use-case.
    
    A leading carmaker would like to build a new car-as-a-sensor service by leveraging fully serverless components
    that are provisioned and managed automatically by AWS. The development team at the carmaker 
    does not want an option that requires the capacity to be manually provisioned, as it does not want to 
    respond manually to changing volumes of sensor data.Given these constraints, which of the 
    following solutions is the BEST fit to develop this car-as-a-sensor service?
        Ingest the sensor data in an Amazon SQS standard queue, which is polled by a Lambda function 
        in batches and the data is written into an auto-scaled DynamoDB table for downstream processing
            Firehose cannot directly write into a DynamoDB table
        
    A news network uses Amazon S3 to aggregate the raw video footage from its reporting teams across the US. 
    The news network has recently expanded into new geographies in Europe and Asia. The technical teams 
    at the overseas branch offices have reported huge delays in uploading large video files to the destination S3 bucket.
    Which of the following are the MOST cost-effective options to improve the file upload speed into S3? 
        Use Amazon S3 Transfer Acceleration to enable faster file uploads into the destination S3 bucket
        Use multipart uploads for faster file uploads into the destination S3 bucket
    
    The solo founder at a tech startup has just created a brand new AWS account. The founder has provisioned
    an EC2 instance 1A which is running in region A. Later, he takes a snapshot of the instance 1A and 
    then creates a new AMI in region A from this snapshot. This AMI is then copied into another region B. 
    The founder provisions an instance 1B in region B using this new AMI in region B.At this point in time, 
    what entities exist in region B?
        1 EC2 instance, 1 AMI and 1 snapshot exist in region B
            When the new AMI is copied from region A into region B, it automatically creates a snapshot in 
            region B because AMIs are based on the underlying snapshots.
    
    A company is in the process of migrating its on-premises SMB file shares to AWS so the company can 
    get out of the business of managing multiple file servers across dozens of offices. The company has 
    200TB of data in its file servers. The existing on-premises applications and native Windows workloads 
    should continue to have low latency access to this data without any disruptions after the migration. 
    The company also wants any new applications deployed on AWS to have access to this migrated data.
        Use Amazon FSx File Gateway to provide low-latency, on-premises access to fully managed file shares 
        in Amazon FSx for Windows File Server. The applications deployed on AWS can access this data directly 
        from Amazon FSx in AWS
            Amazon Storage Gateway’s File Gateway does not support file shares for native Windows workloads
            EFS uses the Network File System version 4 (NFS v4) protocol and it does not support SMB protocol.
        
    A technology blogger wants to write a review on the comparative pricing for various storage types 
    available on AWS Cloud. The blogger has created a test file of size 1GB with some random data. 
    Next he copies this test file into AWS S3 Standard storage class, provisions an EBS volume 
    (General Purpose SSD (gp2)) with 100GB of provisioned storage and copies the test file into 
    the EBS volume, and lastly copies the test file into an EFS Standard Storage filesystem. 
    At the end of the month, he analyses the bill for costs incurred on the respective storage types for the test file.
    What is the correct order of the storage charges incurred for the test file on these three storage types?
        Cost of test file storage on S3 Standard < Cost of test file storage on EFS < Cost of test file storage on EBS
            Amazon EFS, you pay only for the resources that you use. The EFS Standard Storage pricing is 
            $0.30 per GB per month.Therefore the cost for storing the test file on EFS is $0.30 for the month.
            EBS General Purpose SSD (gp2) volumes, the charges are $0.10 per GB-month of provisioned storage.
            Therefore, for a provisioned storage of 100GB for this use-case, the monthly cost on EBS is $0.10*100 = $10. 
            S3 Standard storage, the pricing is $0.023 per GB per month. 
            Therefore, the monthly storage cost on S3 for the test file is $0.023.
    
    The product team at a startup has figured out a market need to support both stateful and stateless 
    client-server communications via the APIs developed using its platform. You have been hired by the 
    startup as a solutions architect to build a solution to fulfill this market need using AWS API Gateway.
    Which of the following would you identify as correct?
        API Gateway creates RESTful APIs that enable stateless client-server communication and API Gateway
        also creates WebSocket APIs that adhere to the WebSocket protocol, which enables stateful, 
        full-duplex communication between client and server
            GET, POST, PUT, PATCH, and DELETE are stateless
    
    The engineering team at a data analytics company has observed that its flagship application functions 
    at its peak performance when the underlying EC2 instances have a CPU utilization of about 50%. 
    The application is built on a fleet of EC2 instances managed under an Auto Scaling group. 
    The workflow requests are handled by an internal Application Load Balancer that routes the requests to the instances.
    As a solutions architect, what would you recommend so that the application runs near its peak performance state?
        Configure the Auto Scaling group to use target tracking policy and set the CPU utilization 
        as the target metric with a target value of 50%
    
    A company has a web application that runs 24*7 in the production environment. The development team at 
    the company runs a clone of the same application in the dev environment for up to 8 hours every day. 
    The company wants to build the MOST cost-optimal solution by deploying these applications using 
    the best-fit pricing options for EC2 instances.
        Use reserved EC2 instances for the production application and on-demand instances for the dev application

    An IT company has built a solution wherein a Redshift cluster writes data to an Amazon S3 bucket belonging
    to a different AWS account. However, it is found that the files created in the S3 bucket using the UNLOAD command
    from the Redshift cluster are not even accessible to the S3 bucket owner.What could be the reason 
    for this denial of permission for the bucket owner?
        By default, an S3 object is owned by the AWS account that uploaded it. 
        So the S3 bucket owner will not implicitly have access to the objects written by Redshift cluster
    
    A social media application is hosted on an EC2 server fleet running behind an Application Load Balancer. 
    The application traffic is fronted by a CloudFront distribution. The engineering team wants to decouple 
    the user authentication process for the application, so that the application servers can just focus 
    on the business logic.As a Solutions Architect, which of the following solutions would you 
    recommend to the development team so that it requires minimal development effort?
        Use Cognito Authentication via Cognito User Pools for your Application Load Balancer
        Application Load Balancer can be used to securely authenticate users for accessing your applications
    
    A systems administrator has created a private hosted zone and associated it with a Virtual Private Cloud (VPC).
    However, the DNS queries for the private hosted zone remain unresolved.As a Solutions Architect, 
    can you identify the Amazon VPC options to be configured in order to get the private hosted zone to work?
        Enable DNS hostnames and DNS resolution for private hosted zones 
    
    "Action": [
        "ec2:RunInstances"
      ],
      "Effect": "Allow",
      "Resource": "*",
      "Condition": {
        "StringEquals": {
          "aws:RequestedRegion": "eu-west-1"
        }
      }
        It allows running EC2 instances only in the eu-west-1 region, and the API call can be made from anywhere in the world
    
    You have multiple AWS accounts within a single AWS Region managed by AWS Organizations and you would 
    like to ensure all EC2 instances in all these accounts can communicate privately. Which of the 
    following solutions provides the capability at the CHEAPEST cost?
        Create a VPC in an account and share one or more of its subnets 
        with the other accounts using Resource Access Manager
    
    A big-data consulting firm is working on a client engagement where the ETL workloads are currently 
    handled via a Hadoop cluster deployed in the on-premises data center. The client wants to migrate 
    their ETL workloads to AWS Cloud. The AWS Cloud solution needs to be highly available with about 50 EC2 
    instances per Availability Zone.As a solutions architect, which of the following EC2 placement groups 
    would you recommend handling the distributed ETL workload?
        Partition placement group
            spreads your instances across logical partitions such that groups of instances in one partition
            do not share the underlying hardware with groups of instances in different partitions. 
            This strategy is typically used by large distributed and replicated workloads, 
            such as Hadoop, Cassandra, and Kafka.
    
    You have a team of developers in your company, and you would like to ensure they can quickly experiment 
    with AWS Managed Policies by attaching them to their accounts, but you would like to prevent them 
    from doing an escalation of privileges, by granting themselves the AdministratorAccess managed policy. 
    How should you proceed?
        For each developer, define an IAM permission boundary that will restrict the 
        managed policies they can attach to themselves
            They can only be applied to roles or users, not IAM groups.
    
    A company has recently launched a new mobile gaming application that the users are adopting rapidly. 
    The company uses RDS MySQL as the database. The engineering team wants an urgent solution 
    to this issue where the rapidly increasing workload might exceed the available database storage.
    As a solutions architect, which of the following solutions would you recommend so that 
    it requires minimum development and systems administration effort to address this requirement?
        Enable storage auto-scaling for RDS MySQL
            Although Aurora offers automatic storage scaling, this option is ruled out since 
            it involves significant systems administration effort to migrate from RDS MySQL to Aurora
        
    A health-care solutions company wants to run their applications on single-tenant hardware 
    to meet regulatory guidelines.Which of the following is the MOST cost-effective 
    way of isolating their Amazon EC2 instances to a single tenant?
        Dedicated Instances
            EC2 instances that run in a virtual private cloud (VPC) on hardware that's dedicated to a single customer
                Dedicated Hosts allow you to use your existing software licenses on EC2 instances and
                you have visibility and control over how instances are placed on the server. 
                This option is costlier than the Dedicated Instance and hence is not the right choice 
                for the current requirement.
    
    An application is currently hosted on four EC2 instances (behind Application Load Balancer) deployed
    in a single Availability Zone (AZ). To maintain an acceptable level of end-user experience, 
    the application needs at least 4 instances to be always available.As a solutions architect, 
    which of the following would you recommend so that the application achieves high availability with MINIMUM cost?
        Deploy the instances in three Availability Zones. Launch two instances in each Availability Zone
            Even if one of the AZs goes out of service, still we shall have 4 instances available 
            and the application can maintain an acceptable level of end-user experience.
    
    Amazon EC2 Auto Scaling needs to terminate an instance from Availability Zone (AZ) us-east-1a as 
    it has the most number of instances amongst the AZs being used currently. There are 4 instances in the 
    AZ us-east-1a like so: Instance A has the oldest launch template, Instance B has the oldest launch configuration,
    Instance C has the newest launch configuration and Instance D is closest to the next billing hour.
    Which of the following instances would be terminated per the default termination policy?
        Instance B
            *aws stopped support for launch configurations 
            Launch template is similar to launch configuration but can enable versioning
            enable you to store the parameters (AMI, instance type, security groups, and key pairs etc.) 
            so that you do not need to define these parameters every time you launch a new instance.
            the first priority is given to any allocation strategy for On-Demand vs Spot instances. 
            As no such information has been provided for the given use-case, so this criterion can be ignored. 
            The next priority is to consider any instance with the oldest launch template unless 
            there is an instance that uses a launch configuration. So this rules out Instance A. 
            Next, you need to consider any instance which has the oldest launch configuration. This implies Instance B
    
    A company has historically operated only in the us-east-1 region and stores encrypted data in S3 using SSE-KMS. 
    As part of enhancing its security posture as well as improving the backup and recovery architecture, 
    the company wants to store the encrypted data in S3 that is replicated into the us-west-1 AWS region. 
    The security policies mandate that the data must be encrypted and decrypted using the same key in both AWS regions.
        Create a new S3 bucket in the us-east-1 region with replication enabled from this new bucket 
        into another bucket in us-west-1 region. Enable SSE-KMS encryption on the new bucket in us-east-1 
        region by using an AWS KMS multi-region key. Copy the existing data from the current S3 bucket 
        in us-east-1 region into this new S3 bucket in us-east-1 region
            you cannot convert an existing single-Region key to a multi-Region key
    
    A manufacturing company receives unreliable service from its data center provider because the company is 
    located in an area prone to natural disasters. The company is not ready to fully migrate to the AWS Cloud, 
    but it wants a failover environment on AWS in case the on-premises data center fails. The company runs web
    servers that connect to external vendors. The data available on AWS and on-premises must be uniform.
    Which of the following solutions would have the LEAST amount of downtime?
        Set up a Route 53 failover record. Run application servers on EC2 instances behind an 
        Application Load Balancer in an Auto Scaling group. Set up AWS Storage Gateway with 
        stored volumes to back up data to S3
            CloudFormation takes time to provision the resources and hence is not the right solution 
            when LEAST amount of downtime is mandated for the given use case.
    
    You have been hired as a Solutions Architect to advise a company on the various authentication/authorization
    mechanisms that AWS offers to authorize an API call within the API Gateway. The company would prefer 
    a solution that offers built-in user management.
        Use Amazon Cognito User Pools
    
    An analytics company wants to improve the performance of its big data processing workflows running on Amazon EFS.
    Which of the following performance modes should be used for EFS to address this requirement?
        Max I/O
            Max I/O performance mode is used to scale to higher levels of aggregate throughput 
            and operations per second. This scaling is done with a tradeoff of slightly higher latencies
            for file metadata operations. Highly parallelized applications and workloads, 
            such as big data analysis, media processing, and genomic analysis, can benefit from this mode.
    
    You would like to migrate an AWS account from an AWS Organization A to an AWS Organization B. 
    What are the steps do to it?
        Remove the member account from the old organization. Send an invite to the member account 
        from the new Organization. Accept the invite to the new organization from the member account
    
    Which of the following AWS services provides a highly available and fault-tolerant solution to capture
    the clickstream events from the source and then provide a concurrent feed of the data stream to the 
    downstream applications?
        AWS Kinesis Data Streams
            read and/or replay records in the same order to multiple Amazon Kinesis Applications
            recommended when you need the ability for multiple applications to consume the same stream concurrently.
            Amazon Kinesis Data Firehose is the easiest way to load streaming data into data stores and 
            analytics tools. It can capture, transform, and load streaming data into Amazon S3, Amazon Redshift, 
            Amazon Elasticsearch Service, and Splunk, enabling near real-time analytics
        
    A leading news aggregation company offers hundreds of digital products and services for customers 
    ranging from law firms to banks to consumers. The company bills its clients based on per unit of 
    clickstream data provided to the clients. As the company operates in a regulated industry, 
    it needs to have the same ordered clickstream data available for auditing within a window of 7 days.
    As a solutions architect, which of the following AWS services provides the ability to run the 
    billing process and auditing process on the given clickstream data in the same order?
        AWS Kinesis Data Streams
        
    A company has a hybrid cloud structure for its on-premises data center and AWS Cloud infrastructure. 
    The company wants to build a web log archival solution such that only the most frequently accessed logs 
    are available as cached data locally while backing up all logs on Amazon S3.As a solutions architect,
    which of the following solutions would you recommend for this use-case?
        Use AWS Volume Gateway - Cached Volume - to store the most frequently accessed logs locally 
        for low-latency access while storing the full volume with all logs in its Amazon S3 service bucket
            AWS Volume Gateway stores the full volume in its Amazon S3 service bucket, and 
            just the recently accessed data is retained in the gateway’s local cache for low-latency access.
    
    A leading bank has moved its IT infrastructure to AWS Cloud and they have been using Amazon EC2 Auto Scaling
    for their web servers. This has helped them deal with traffic spikes effectively. But, their MySQL 
    relational database has now become a bottleneck and they urgently need a fully managed auto scaling solution 
    for their relational database to address any unpredictable changes in the traffic.
        Amazon Aurora Serverless
            It's a simple, cost-effective option for infrequent, intermittent, or unpredictable workloads.
    
    An IT consultant is helping a small business revamp their technology infrastructure on the AWS Cloud. 
    The business has two AWS accounts and all resources are provisioned in the us-west-2 region. 
    The IT consultant is trying to launch an EC2 instance in each of the two AWS accounts such that the 
    instances are in the same Availability Zone of the us-west-2 region. Even after selecting the same 
    default subnet (us-west-2a) while launching the instances in each of the AWS accounts, the IT consultant 
    notices that the Availability Zones are still different.
        Use AZ ID to uniquely identify the Availability Zones across the two AWS Accounts
            To ensure that resources are distributed across the Availability Zones for a region, 
            AWS maps Availability Zones to names for each AWS account. For example, the Availability Zone
            us-west-2a for one AWS account might not be the same location as us-west-2a for another AWS account.
            ex: usw2-az2 is an AZ ID for the us-west-2 region
    
    A company wants to improve its gaming application by adding a leaderboard that uses a complex proprietary 
    algorithm based on the participating user's performance metrics to identify the top users on a real-time basis.
    The technical requirements mandate high elasticity, low latency, and real-time processing to deliver 
    customizable user data for the community of users. The leaderboard would be accessed by millions of users 
    simultaneously.Which of the following options support the case for using ElastiCache to meet the given requirements? 
        Use ElastiCache to improve latency and throughput for read-heavy application workloads
        Use ElastiCache to improve the performance of compute-intensive workloads
    
    The engineering team at a social media company wants to use Amazon CloudWatch alarms to automatically 
    recover EC2 instances if they become impaired. The team has hired you as a solutions architect to provide
    subject matter expertise.As a solutions architect, which of the following statements would 
    you identify as CORRECT regarding this automatic recovery process?
        A recovered instance is identical to the original instance, including the instance ID, private IP addresses, 
        Elastic IP addresses, and all instance metadata
        If your instance has a public IPv4 address, it retains the public IPv4 address after recovery
    
    The development team at a retail company wants to optimize the cost of EC2 instances. The team wants to move 
    certain nightly batch jobs to spot instances. The team has hired you as a solutions architect to 
    provide the initial guidance.Which of the following would you identify as CORRECT regarding 
    the capabilities of spot instances?
        If a spot request is persistent, then it is opened again after your Spot Instance is interrupted
        Spot blocks are designed not to be interrupted
        When you cancel an active spot request, it does not terminate the associated instance
            A Spot Instance request is either one-time or persistent. If the spot request is persistent, 
            the request is opened again after your Spot Instance is interrupted. If the request is 
            persistent and you stop your Spot Instance, the request only opens after you start your Spot Instance.
    
    A media streaming company is looking to migrate its on-premises infrastructure into the AWS Cloud. 
    The engineering team is looking for a fully managed NoSQL persistent data store with in-memory 
    caching to maintain low latency that is critical for real-time scenarios such as video streaming and 
    interactive content. The team expects the number of concurrent users to touch up to a million so the 
    database should be able to scale elastically.
        DynamoDB
            Elasticache is used as a caching layer. It's not a fully managed NoSQL database.

    A global manufacturing company with facilities in the US, Europe, and Asia is designing a new distributed 
    application to optimize its procurement workflow. The orders booked in one AWS Region should be visible
    to all AWS Regions in a second or less. The database should be able to facilitate failover with a 
    short Recovery Time Objective (RTO). The uptime of the application is critical to ensure that the 
    manufacturing processes are not impacted.
        Provision Amazon Aurora Global Database
            provides more comprehensive failover capabilities than the failover provided by a default Aurora DB cluster. 
            DynamoDB global tables due to the active-active configuration of DynamoDB global tables, there is no concept of failover 
            because the application writes to the table in its region, and then the data is replicated 
            to keep the other regions' table in sync. DynamoDB global tables is a much costlier solution 
            than Aurora Global Database for the given requirement.
    
    A video conferencing application is hosted on a fleet of EC2 instances which are part of an Auto Scaling group (ASG).
    The ASG uses a Launch Configuration (LC1) with "dedicated" instance placement tenancy but the VPC (V1) used by
    the Launch Configuration LC1 has the instance tenancy set to default. Later the DevOps team creates a new 
    Launch Configuration (LC2) with "default" instance placement tenancy but the VPC (V2) used by the 
    Launch Configuration LC2 has the instance tenancy set to dedicated.Which of the following is correct 
    regarding the instances launched via Launch Configuration LC1 and Launch Configuration LC2?
        The instances launched by both Launch Configuration LC1 and Launch Configuration LC2 will have 
        dedicated instance tenancy
            When you create a launch configuration, the default value for the instance placement tenancy is null 
            and the instance tenancy is controlled by the tenancy attribute of the VPC. If you set the 
            Launch Configuration Tenancy to default and the VPC Tenancy is set to dedicated, 
            then the instances have dedicated tenancy. If you set the Launch Configuration Tenancy to 
            dedicated and the VPC Tenancy is set to default, then again the instances have dedicated tenancy.
            If either Launch Configuration Tenancy or VPC Tenancy is set to dedicated, then the 
            instance tenancy is also dedicated.
    
    A media startup is looking at hosting their web application on AWS Cloud. The application will be accessed 
    by users from different geographic regions of the world to upload and download video files that can 
    reach a maximum size of 10GB. The startup wants the solution to be cost-effective and scalable with 
    the lowest possible latency for a great user experience.
        Use Amazon S3 for hosting the web application and use S3 Transfer Acceleration to reduce the latency 
        that geographically dispersed users might face
            If you have objects that are smaller than 1GB or if the data set is less than 1GB in size, 
            you should consider using Amazon CloudFront's PUT/POST commands for optimal performance.
    
    The engineering team at an e-commerce company wants to migrate from SQS Standard queues to FIFO queues with batching.
    As a solutions architect, which of the following steps would you have in the migration checklist?
        Delete the existing standard queue and recreate it as a FIFO queue
        Make sure that the name of the FIFO queue ends with the .fifo suffix
        Make sure that the throughput for the target FIFO queue does not exceed 3,000 messages per second
            By default, FIFO queues support up to 3,000 messages per second with batching, or up to 300 messages
            per second (300 send, receive, or delete operations per second) without batching. 
            Therefore, using batching you can meet a throughput requirement of upto 3,000 messages per second.
        
    An IT company is looking to move its on-premises infrastructure to AWS Cloud. The company has a portfolio
    of applications with a few of them using server bound licenses that are valid for the next year. 
    To utilize the licenses, the CTO wants to use dedicated hosts for a one year term and then migrate 
    the given instances to default tenancy thereafter.As a solutions architect, which of the following options
    would you identify as CORRECT for changing the tenancy of an instance after you have launched it?
        You can change the tenancy of an instance from dedicated to host
        You can change the tenancy of an instance from host to dedicated
    
    A media company wants a low-latency way to distribute live sports results which are delivered via a
    proprietary application using UDP protocol.As a solutions architect, which of the following solutions 
    would you recommend such that it offers the BEST performance for this use case?
        Use Global Accelerator to provide a low latency way to distribute live sports results
            Global Accelerator is a good fit for non-HTTP use cases, such as gaming (UDP), IoT (MQTT), or Voice over IP.
    
    A company has set up "AWS Organizations" to manage several departments running their own AWS accounts. 
    The departments operate from different countries and are spread across various AWS Regions. 
    The company wants to set up a consistent resource provisioning process across departments so that each resource
    follows pre-defined configurations such as using a specific type of EC2 instances, specific IAM roles for 
    Lambda functions, etc.
        Use AWS CloudFormation StackSets to deploy the same template across AWS accounts and regions
            extends the functionality of stacks by enabling you to create, update, or delete stacks across 
            multiple accounts and regions with a single operation. A stack set lets you create stacks in 
            AWS accounts across regions by using a single AWS CloudFormation template
    
    An IT company is using SQS queues for decoupling the various components of application architecture. 
    As the consuming components need additional time to process SQS messages, the company wants to 
    postpone the delivery of new messages to the queue for a few seconds.
        Use delay queues to postpone the delivery of new messages to the queue for a few seconds
            If you create a delay queue, any messages that you send to the queue remain invisible to 
            consumers for the duration of the delay period. The default (minimum) delay for a queue is 0 seconds.
            The maximum is 15 minutes.
    
    An e-commerce company runs its web application on EC2 instances in an Auto Scaling group and it's configured
    to handle consumer orders in an SQS queue for downstream processing. The DevOps team has observed 
    that the performance of the application goes down in case of a sudden spike in orders received.
        Use a target tracking scaling policy based on a custom Amazon SQS queue metric
    
    A financial services company wants to identify any sensitive data stored on its Amazon S3 buckets. 
    The company also wants to monitor and protect all data stored on S3 against any malicious activity.
        Use Amazon GuardDuty to monitor any malicious activity on data stored in S3. 
        Use Amazon Macie to identify any sensitive data stored on S3
    
    An e-commerce company is using an Elastic Load Balancer for its fleet of EC2 instances spread across 
    two Availability Zones, with one instance as a target in Availability Zone A and four instances as 
    targets in Availability Zone B. The company is doing benchmarking for server performance 
    when cross-zone load balancing is enabled compared to the case when cross-zone load balancing is disabled.
    As a solutions architect, which of the following traffic distribution outcomes would you identify as correct?
        With cross-zone load balancing enabled, one instance in Availability Zone A receives 20% traffic 
        and four instances in Availability Zone B receive 20% traffic each. With cross-zone load balancing 
        disabled, one instance in Availability Zone A receives 50% traffic and four instances in Availability
        Zone B receive 12.5% traffic each
            When cross-zone load balancing is enabled, each load balancer node distributes traffic across 
            the registered targets in all enabled Availability Zones. Therefore, one instance in 
            Availability Zone A receives 20% traffic and four instances in Availability Zone B receive 20%
            traffic each. When cross-zone load balancing is disabled, each load balancer node distributes 
            traffic only across the registered targets in its Availability Zone. Therefore, 
            one instance in Availability Zone A receives 50% traffic and four instances in Availability Zone B
            receive 12.5% traffic each.
        
    A startup has created a new web application for users to complete a risk assessment survey for COVID-19 
    symptoms via a self-administered questionnaire. The startup has purchased the domain covid19survey.com
    using Route 53. The web development team would like to create a Route 53 record so that all 
    traffic for covid19survey.com is routed to www.covid19survey.com.As a solutions architect, which of 
    the following is the MOST cost-effective solution that you would recommend to the web development team?
        Create an alias record for covid19survey.com that routes traffic to www.covid19survey.com
            You can create an alias record at the top node of a DNS namespace, also known as the zone apex,
            however, you cannot create a CNAME record for the top node of the DNS namespace. 
            So, if you register the DNS name covid19survey.com, the zone apex is covid19survey.com. 
            You can't create a CNAME record for covid19survey.com, but you can create an alias record 
            for covid19survey.com that routes traffic to www.covid19survey.com.
    
    An AWS Organization is using Service Control Policies (SCP) for central control over the maximum available 
    permissions for all accounts in their organization. This allows the organization to ensure that all 
    accounts stay within the organization’s access control guidelines.
        If a user or role has an IAM permission policy that grants access to an action that is either 
        not allowed or explicitly denied by the applicable SCPs, the user or role can't perform that action
        SCPs affect all users and roles in attached accounts, including the root user
        SCPs do not affect service-linked role
    
    A digital media company needs to manage uploads of around 1TB each from an application being used by a partner company.
        Use multi-part upload feature of Amazon S3
            Snowball device had 80TB of storage space which is much higher than required 
    
    You are working for a SaaS (Software as a Service) company as a solutions architect and help design solutions
    for the company's customers. One of the customers is a bank and has a requirement to whitelist up to 
    two public IPs when the bank is accessing external services across the internet.Which architectural choice
    do you recommend to maintain high availability, support scaling-up to 10 instances and comply with the bank's requirements?
        Use a Network Load Balancer with an Auto Scaling Group (ASG) 
            expose a fixed IP to the public web
    
    You are working as an AWS architect for a weather tracking facility. You are asked to set up a Disaster Recovery
    (DR) mechanism with minimum costs. In case of failure, the facility can only bear data loss of a few minutes 
    without jeopardizing the forecasting models.
        Pilot Light
            The term pilot light is often used to describe a DR scenario in which a minimal version of an 
            environment is always running in the cloud
            Warm Standby is more costly compared to Pilot Light.
    
    A social media company wants the capability to dynamically alter the size of a geographic area from which 
    traffic is routed to a specific server resource
        Geoproximity routing
            Geoproximity routing lets Amazon Route 53 route traffic to your resources based on the 
            geographic location of your users and your resources. You can also optionally choose to 
            route more traffic or less to a given resource by specifying a value, known as a bias. 
            A bias expands or shrinks the size of the geographic region from which traffic is routed to a resource.
    
    A systems administrator is creating IAM policies and attaching them to IAM identities. After creating the 
    necessary identity-based policies, the administrator is now creating resource-based policies.Which is the 
    only resource-based policy that the IAM service supports?
        Trust policy
            Trust policies define which principal entities (accounts, users, roles, and federated users) 
            can assume the role. An IAM role is both an identity and a resource that supports resource-based 
            policies. For this reason, you must attach both a trust policy and an identity-based policy 
            to an IAM role. The IAM service supports only one type of resource-based policy called a 
            role trust policy, which is attached to an IAM role.
    
    A healthcare company is evaluating storage options on Amazon S3 to meet regulatory guidelines. 
    The data should be stored in such a way on S3 that it cannot be deleted until the regulatory time period has expired.
        Use S3 Object Lock
            allows you to store objects using a write once, read many (WORM) model
            S3 Glacier Vault Lock is only for Glacier and not for S3
    
    A company has developed a popular photo-sharing website using a serverless pattern on the AWS Cloud using API Gateway 
    and AWS Lambda. The backend uses an RDS PostgreSQL database. The website is experiencing high read traffic 
    and the Lambda functions are putting an increased read load on the RDS database.The architecture team
    is planning to increase the read throughput of the database, without changing the application's core logic
        Use Amazon RDS Read Replicas
            provide enhanced performance and durability for RDS database (DB) instances.
            Amazon RDS Multi-AZ provide enhanced availability and durability for RDS database
    
    A CRM web application was written as a monolith in PHP and is facing scaling issues because of performance 
    bottlenecks. The CTO wants to re-engineer towards microservices architecture and expose their application 
    from the same load balancer, linked to different target groups with different URLs: checkout.mycorp.com, 
    www.mycorp.com, yourcorp.com/profile and yourcorp.com/search. The CTO would like to expose all these 
    URLs as HTTPS endpoints for security purposes.As a solutions architect, which of the following would you 
    recommend as a solution that requires MINIMAL configuration effort?
        Use SSL certificates with SNI
            SNI support AWS makes it easy to use more than one certificate with the same ALB.
            As the use case requires different domain names, so you cannot use a wildcard SSL certificate.
    
    A CRM company has a SaaS (Software as a Service) application that feeds updates to other in-house and 
    third-party applications. The SaaS application and the in-house applications are being migrated 
    to use AWS services for this inter-application communication.
        Use Amazon EventBridge to decouple the system architecture
            Amazon EventBridge is recommended when you want to build an application that reacts to events 
            from SaaS applications and/or AWS services. Amazon EventBridge is the only event-based service 
            that integrates directly with third-party SaaS partners. 
            Both Amazon EventBridge and Amazon SNS can be used to develop event-driven applications, 
            but for this use case, EventBridge is the right fit.

    A photo hosting service publishes a collection of beautiful mountain images, every month, that aggregate
    over 50 GB in size and downloaded all around the world. The content is currently hosted on EFS and 
    distributed by Elastic Load Balancing (ELB) and Amazon EC2 instances. The website is experiencing high 
    load each month and very high network costs.As a Solutions Architect, what can you recommend that won't 
    force an application refactor and reduce network costs and EC2 load drastically?
        Create a CloudFront distribution
            create a CloudFront distribution to add a caching layer in front of your ELB.
    
    As part of the on-premises data center migration to AWS Cloud, a company is looking at using multiple 
    AWS Snow Family devices to move their on-premises data.Which Snow Family service offers the feature of 
    storage clustering?
        AWS Snowball Edge Compute Optimized
            both AWS Snowball Edge Storage Optimized and AWS Snowball Edge Compute Optimized 
            offer the storage clustering feature
    
    The engineering team at a social media company has recently migrated to AWS Cloud from its on-premises 
    data center. The team is evaluating CloudFront to be used as a CDN for its flagship application. The team 
    has hired you as an AWS Certified Solutions Architect Associate to advise on CloudFront capabilities 
    on routing, security, and high availability.
        CloudFront can route to multiple origins based on the content type
        Use an origin group with primary and secondary origins to configure CloudFront for high availability and failover
        Use field level encryption in CloudFront to protect sensitive data for specific content
    
    A company runs a popular dating website on the AWS Cloud. As a Solutions Architect, you've designed the 
    architecture of the website to follow a serverless pattern on the AWS Cloud using API Gateway and AWS Lambda.
    The backend uses an RDS PostgreSQL database. Currently, the application uses a username and password combination
    to connect the Lambda function to the RDS database.You would like to improve the security 
    at the authentication level by leveraging short-lived credentials.
        Use IAM authentication from Lambda to RDS PostgreSQL
        Attach an AWS Identity and Access Management (IAM) role to AWS Lambda
    
    A company has noticed that its EBS storage volume (io1) accounts for 90% of the cost and the remaining 10% cost 
    can be attributed to the EC2 instance. The CloudWatch metrics report that both the EC2 instance and the EBS volume
    are under-utilized. The CloudWatch metrics also show that the EBS volume has occasional I/O bursts. 
    The entire infrastructure is managed by AWS CloudFormation.As a Solutions Architect, what do you propose 
    to reduce the costs?
        Convert the Amazon EC2 instance EBS volume to gp2
            Changing the EC2 instance type to something much smaller won't affect 90% of the costs that are incurred
    
    An Internet-of-Things (IoT) company would like to have a streaming system that performs real-time analytics
    on the ingested IoT data. Once the analytics is done, the company would like to send notifications 
    back to the mobile applications of the IoT device owners.As a solutions architect, which of the following
    AWS technologies would you recommend to send these notifications to the mobile applications?
        Amazon Kinesis with Amazon Simple Notification Service (SNS)
                Simple Email Service (Amazon SES) is an email service and not a notification service
    
    As an e-sport tournament hosting company, you have servers that need to scale and be highly available. 
    Therefore you have deployed an Elastic Load Balancer (ELB) with an Auto Scaling group (ASG) across
    3 Availability Zones (AZs). When e-sport tournaments are running, the servers need to scale quickly. 
    And when tournaments are done, the servers can be idle. As a general rule, you would like to be 
    highly available, have the capacity to scale and optimize your costs.
        Set the minimum capacity to 2
            though our ASG is deployed across 3 AZs, the minimum capacity to be highly available is 2. 
            When we specify 2 as the minimum capacity, the ASG would create these 2 instances in separate AZs.
        Use Reserved Instances for the minimum capacity
    
    A leading video streaming provider is migrating to AWS Cloud infrastructure for delivering its content to 
    users across the world. The company wants to make sure that the solution supports at least a million requests
    per second for its EC2 server farm.As a solutions architect, which type of Elastic Load Balancer 
    would you recommend as part of the solution stack?
        Network Load Balancer
            best suited for use-cases involving low latency and high throughput workloads that involve 
            scaling to millions of requests per second.
    
    A health-care company manages its web application on Amazon EC2 instances running behind Auto Scaling group (ASG).
    The company provides ambulances for critical patients and needs the application to be reliable. 
    The workload of the company can be managed on 2 EC2 instances and can peak up to 6 instances when traffic increases.
    As a Solutions Architect, which of the following configurations would you select as the best fit for these requirements?
        The ASG should be configured with the minimum capacity set to 4, with 2 instances each in two different
        Availability Zones. The maximum capacity of the ASG should be set to 6
    
    A financial services company is moving its IT infrastructure to AWS Cloud and wants to enforce adequate 
    data protection mechanisms on Amazon S3 to meet compliance guidelines. The engineering team has 
    hired you as a solutions architect to build a solution for this requirement.Can you help the team identify the 
    INCORRECT option from the choices below?
        S3 can encrypt object metadata by using Server-Side Encryption
            Metadata – A set of name-value pairs with which you can store information regarding the object.
            is not encrypted while being stored on Amazon S3. AWS recommends that customers not place 
            sensitive information in Amazon S3 metadata.
    
    A junior developer is learning to build websites using HTML, CSS, and JavaScript. He has created a static 
    website and then deployed it on Amazon S3. Now he can't seem to figure out the endpoint for his super cool website.
    As a solutions architect, can you help him figure out the allowed formats for the Amazon S3 website endpoints?
        http://bucket-name.s3-website.Region.amazonaws.com
        http://bucket-name.s3-website-Region.amazonaws.com
    
    A financial services firm uses a high-frequency trading system and wants to write the log files into Amazon S3.
    The system will also read these log files in parallel on a near real-time basis. The engineering 
    team wants to address any data discrepancies that might arise when the trading system overwrites an 
    existing log file and then tries to read that specific log file.
        A process replaces an existing object and immediately tries to read it. 
        Amazon S3 always returns the latest version of the object
    
    A mobile chat application uses DynamoDB as its database service to provide low latency chat updates. 
    A new developer has joined the team and is reviewing the configuration settings for DynamoDB which 
    have been tweaked for certain technical requirements. CloudTrail service has been enabled on all 
    the resources used for the project. Yet, DynamoDB encryption details are nowhere to be found.
        By default, all DynamoDB tables are encrypted under an AWS owned customer master key (CMK), 
        which do not write to CloudTrail logs
    
    While troubleshooting, a cloud architect realized that the Amazon EC2 instance is unable to connect to 
    the internet using the Internet Gateway.Which conditions should be met for internet connectivity to be established?
        The network ACLs associated with the subnet must have rules to allow inbound and outbound traffic
            allow inbound and outbound traffic on port 80 (for HTTP traffic) and port 443 (for HTTPs traffic).
        The route table in the instance’s subnet should have a route to an Internet Gateway
    
    A leading media company wants to do an accelerated online migration of hundreds of terabytes of files from 
    their on-premises data center to Amazon S3 and then establish a mechanism to access the migrated data for 
    ongoing updates from the on-premises applications.As a solutions architect, which of the 
    following would you select as the MOST performant solution for the given use-case?
        Use AWS DataSync to migrate existing data to Amazon S3 and then use File Gateway to retain access 
        to the migrated data for ongoing updates from the on-premises applications
            AWS DataSync is an online data transfer service that simplifies, automates, and accelerates 
            copying large amounts of data to and from AWS storage services over the internet or AWS Direct Connect.
            File gateway offers SMB or NFS-based access to data in Amazon S3 with local caching.

    Which of the following is true regarding cross-zone load balancing as seen in Application Load Balancer 
    versus Network Load Balancer?
        By default, cross-zone load balancing is enabled for Application Load Balancer 
        and disabled for Network Load Balancer
            When cross-zone load balancing is enabled, each load balancer node distributes traffic 
            across the registered targets in all the enabled Availability Zones. 
            When cross-zone load balancing is disabled, each load balancer node distributes traffic 
            only across the registered targets in its Availability Zone.
    
    A company wants to publish an event into an SQS queue whenever a new object is uploaded on S3.
        Only Standard SQS queue is allowed as an Amazon S3 event notification destination, whereas FIFO SQS queue is not allowed
    
    A company's cloud architect has set up a solution that uses Route 53 to configure the DNS records for the primary
    website with the domain pointing to the Application Load Balancer (ALB). The company wants a solution where 
    users will be directed to a static error page, configured as a backup, in case of unavailability of the primary website.
    Which configuration will meet the company's requirements, while keeping the changes to a bare minimum?
        Set up a Route 53 active-passive type of failover routing policy. If Route 53 health check determines 
        the ALB endpoint as unhealthy, the traffic will be diverted to a static error page, hosted on Amazon S3 bucket
    
    An application hosted on Amazon EC2 contains sensitive personal information about all its customers and needs
    to be protected from all types of cyber-attacks. The company is considering using the AWS Web Application 
    Firewall (WAF) to handle this requirement.Can you identify the correct solution leveraging the capabilities of WAF?
        Create a CloudFront distribution for the application on Amazon EC2 instances. 
        Deploy AWS WAF on Amazon CloudFront to provide the necessary safety measures
    
    A media company is evaluating the possibility of moving its IT infrastructure to the AWS Cloud. The company needs 
    at least 10 TB of storage with the maximum possible I/O performance for processing certain files which are 
    mostly large videos. The company also needs close to 450 TB of very durable storage for storing media content 
    and almost double of it, i.e. 900 TB for archival of legacy data.
        Amazon EC2 instance store for maximum performance, Amazon S3 for durable data storage, 
        and Amazon S3 Glacier for archival storage
    
    A company wants to ensure high availability for its RDS database. The development team wants to opt for 
    Multi-AZ deployment and they would like to understand what happens when the primary instance of the Multi-AZ
    configuration goes down.
        The CNAME record will be updated to point to the standby DB
            Failover is automatically handled by Amazon RDS so that you can resume database operations as quickly
            as possible without administrative intervention. When failing over, Amazon RDS simply flips the canonical
            name record (CNAME) for your DB instance to point at the standby, which is in turn promoted to 
            become the new primary. Multi-AZ means the URL is the same, the failover is automated, and the 
            CNAME will automatically be updated to point to the standby database.

    An e-commerce website is migrating towards a microservices-based approach for their website and plans to 
    expose their website from the same load balancer, linked to different target groups with different 
    URLs: checkout.mycorp.com, www.mycorp.com, mycorp.com/products, and mycorp.com/orders. The website would 
    like to use ECS on the backend to manage these microservices and possibly host the same container of the 
    application multiple times on the same EC2 instance.
        Application Load Balancer + dynamic port mapping
            Application Load Balancer can automatically distribute incoming application traffic across 
            multiple targets, such as Amazon EC2 instances, containers, IP addresses, and Lambda functions. 
            It can handle the varying load of your application traffic in a single Availability Zone or across 
            multiple Availability Zones.
            Dynamic port mapping with an Application Load Balancer makes it easier to run multiple tasks 
            on the same Amazon ECS service on an Amazon ECS cluster.
    
    A big data analytics company is looking to archive the on-premises data into a POSIX compliant file storage 
    system on AWS Cloud. The archived data would be accessed for just about a week in a year.
    MOST cost-optimal solution?
        EFS Infrequent Access
    
    The DevOps team at a major financial services company uses Multi-Availability Zone (Multi-AZ) deployment 
    for its MySQL RDS database in order to automate its database replication and augment data durability. 
    The DevOps team has scheduled a maintenance window for a database engine level upgrade for the coming weekend.
    Which of the following is the correct outcome during the maintenance window?
        Any database engine level upgrade for an RDS DB instance with Multi-AZ deployment triggers both the primary 
        and standby DB instances to be upgraded at the same time. This causes downtime until the upgrade is complete
    
    An application running on an EC2 instance needs to access a DynamoDB table in the same AWS account.
        Set up an IAM service role with the appropriate permissions to allow access to the DynamoDB table. 
        Configure an instance profile to assign this IAM role to the EC2 instance

    A company has noticed several provisioned throughput exceptions on its DynamoDB database due to major 
    spikes in the writes to the database. The development team wants to decouple the application layer 
    from the database layer and dedicate a worker process to writing the data to DynamoDB.
    Which middleware do you recommend on using that can scale infinitely and meet these 
    requirements in the most cost effective way?
        Amazon Simple Queue Service (SQS)
    
    A social media application lets users upload photos and perform image editing operations. 
    The application offers two classes of service: pro and lite. The product team wants the photos 
    submitted by pro users to be processed before those submitted by lite users. Photos are uploaded to 
    S3 and the job information is sent to Amazon SQS.
        Create two SQS standard queues: one for pro and one for lite. Set up EC2 instances to prioritize 
        polling for the pro queue over the lite queue
    
    A data analytics company is running a proprietary database on an EC2 instance using EBS volumes. 
    The database is heavily I/O bound. As a solutions architect, which of the following 
    RAID configurations would you recommend improving the I/O performance?
        Use RAID 0 when I/O performance is more important than fault tolerance
            With Amazon EBS, you can use any of the standard RAID configurations that you can use 
            with a traditional bare metal server, as long as that particular RAID configuration 
            is supported by the operating system for your instance. This is because all RAID is accomplished
            at the software level.
            RAID 1 when fault tolerance is more important than I/O performance
    
    A Big Data consulting company runs large distributed and replicated workloads on the on-premises data center. 
    The company now wants to move these workloads to Amazon EC2 instances by using the placement groups 
    feature and it wants to minimize correlated hardware failures.
        Partition placement groups
            Amazon EC2 divides each group into logical segments called partitions. Amazon EC2 ensures 
            that each partition within a placement group has its own set of racks. Each rack has its own 
            network and power source. No two partitions within a placement group share the same racks, 
            allowing you to isolate the impact of a hardware failure within your application.
        
    A digital media streaming company wants to use AWS Cloudfront to distribute its content only to 
    its service subscribers. As a solutions architect, which of the following solutions would you suggest
    to deliver restricted content to the bona fide end users?
        Use CloudFront signed URLs
        Use CloudFront signed cookies

    The DevOps team at an e-commerce company has deployed a fleet of EC2 instances under an Auto Scaling group (ASG). 
    The instances under the ASG span two Availability Zones (AZ) within the us-east-1 region. All the incoming requests 
    are handled by an Application Load Balancer (ALB) that routes the requests to the EC2 instances under the ASG. 
    As part of a test run, two instances (instance 1 and 2, belonging to AZ A) were manually terminated by the 
    DevOps team causing the Availability Zones to become unbalanced. Later that day, another instance 
    (belonging to AZ B) was detected as unhealthy by the Application Load Balancer's health check.
        As the Availability Zones got unbalanced, Amazon EC2 Auto Scaling will compensate by rebalancing the Availability
        Zones. When rebalancing, Amazon EC2 Auto Scaling launches new instances before terminating the old ones,
        so that rebalancing does not compromise the performance or availability of your application
        Amazon EC2 Auto Scaling creates a new scaling activity for terminating the unhealthy instance and then terminates it. 
        Later, another scaling activity launches a new instance to replace the terminated instance
    
    The engineering team at a multi-national company uses AWS Firewall Manager to centrally configure and manage
    firewall rules across its accounts and applications using AWS Organizations.Which of the following AWS 
    resources can the AWS Firewall Manager configure rules on?
        AWS WAF
        AWS Shield Advanced
        VPC Security Groups
            Firewall Manager doesn't support Network Access Control Lists (NACLs)
            as this is optional layer of security
        
    The engineering team at a startup is evaluating the most optimal block storage volume type for the EC2 
    instances hosting its flagship application. The storage volume should support very low latency but it 
    does not need to persist the data when the instance terminates. As a solutions architect, you have 
    proposed using Instance Store volumes to meet these requirements.
        You can't detach an instance store volume from one instance and attach it to a different instance
        If you create an AMI from an instance, the data on its instance store volumes isn't preserved
    
    A Big Data analytics company is using a fleet of Amazon EC2 instances to ingest Internet-of-Things 
    (IoT) data from various data sources. The data is in JSON format and ingestion rates can be as high 
    as 1 MB/s. When an EC2 instance is restarted, the in-flight data is lost. The analytics team at the company 
    wants to store as well as query the ingested data in near-real-time.Which of the following solutions 
    provides near-real-time data querying that is scalable with minimal data loss?
        Capture data in Amazon Kinesis Data Firehose with Amazon Redshift as the destination. 
        Use Amazon Redshift to query the data
    
    A company has moved its business critical data to Amazon EFS file system which will be accessed by multiple 
    EC2 instances. As an AWS Certified Solutions Architect Associate, which of the following would you recommend 
    to exercise access control such that only the permitted EC2 instances can read from the EFS file system? 
        Use VPC security groups to control the network traffic to and from your file system
        Use an IAM policy to control access for clients who can mount your file system with the required permissions
    
    You are deploying a critical monolith application that must be deployed on a single web server, 
    as it hasn't been created to work in distributed mode. Still, you want to make sure your setup can 
    automatically recover from the failure of an AZ.Which of the following options should be combined to 
    form the MOST cost-efficient solution? 
        Create an auto-scaling group that spans across 2 AZ, which min=1, max=1, desired=1
            An ASG with desired=2 would create two instances, and this won't work for us as our 
            monolith application is not made to work with two instances as per the given use-case.
        Create an Elastic IP and use the EC2 user-data script to attach it
            you can mask the failure of an instance or software by rapidly remapping the address 
            to another instance in your account.
            If we use an ALB, things will still work, but we will have to pay for the provisioned 
            ALB which sends traffic to only one EC2 instance. Instead, to minimize costs, we must use an Elastic IP.
        Assign an EC2 Instance Role to perform the necessary API calls
            For that Elastic IP to be attached to our EC2 instance, we must use an EC2 user data script, and 
            our EC2 instance must have the correct IAM permissions to perform the API call, so we need an EC2 instance role.
    
    You are looking to build an index of your files in S3, using Amazon RDS PostgreSQL. To build this index, 
    it is necessary to read the first 250 bytes of each object in S3, which contains some metadata about the 
    content of the file itself. There are over 100,000 files in your S3 bucket, amounting to 50TB of data.
        Create an application that will traverse the S3 bucket, issue a Byte Range Fetch for the 
        first 250 bytes, and store that information in RDS
            Using the Range HTTP header in a GET Object request, you can fetch a byte-range from an object, 
            transferring only the specified portion. You can use concurrent connections to Amazon S3 to 
            fetch different byte ranges from within the same object.
            You cannot use Byte Range Fetch parameter with S3 Select to traverse the S3 bucket and get 
            the first bytes of a file.
        
    The engineering team at a company wants to create a daily big data analysis job leveraging Spark for analyzing 
    online/offline sales and customer loyalty data to create customized reports on a client-by-client basis. 
    The big data analysis job needs to read the data from Amazon S3 and output it back to S3.
    Which technology do you recommend to run the Big Data analysis job?
        Amazon EMR
        AWS Glue
    
    A software engineering intern at a company is documenting the features offered by EC2 Spot instances, 
    Spot blocks, and Spot Fleets.Can you help the intern by selecting the correct options that identify the 
    key characteristics of these three types of Spot entities?
        Spot instances are spare EC2 capacity that can save you up 90% off of On-Demand prices. 
        Spot instances can be interrupted by Amazon EC2 for capacity requirements with a 2-minute notification
        Spot blocks allow you to request Amazon EC2 Spot instances for 1 to 6 hours at a time to avoid being interrupted
        A Spot Fleet is a set of Spot Instances and optionally On-Demand Instances that are launched 
        to meet your target capacity

    A development team wants to ensure that all objects uploaded to an Amazon S3 bucket are encrypted?
        Configure the bucket policy to deny if the PutObject does not have an x-amz-server-side-encryption header set
            There are two possible values for the x-amz-server-side-encryption header: AES256, which tells S3 to 
            use S3-managed keys, and aws:kms, which tells S3 to use AWS KMS–managed keys.
            By default, Amazon S3 allows both HTTP and HTTPS requests. aws:SecureTransport key is 
            used to check if the request is sent through HTTP or HTTPS. When this key is true, it means 
            that the request is sent through HTTPS
    
    A development team is looking for a solution that saves development time and deployment costs for 
    an application that uses a high-throughput request-response message pattern.Which of the following 
    SQS queue types is the best fit to meet this requirement?
        Amazon SQS temporary queues
    
    To support critical production workloads that require maximum resiliency, a company wants to 
    configure network connections between its Amazon VPC and the on-premises infrastructure. 
    The company needs AWS Direct Connect connections with speeds greater than 1 Gbps.As a solutions architect,
    which of the following will you suggest as the best architecture for this requirement?
        Opt for two separate Direct Connect connections terminating on separate devices in 
        more than one Direct Connect location
            Maximum resilience is achieved by separate connections terminating on separate devices
            in more than one location
            AWS does not recommend customers use AWS Managed VPN as a backup for AWS Direct Connect
            connections with speeds greater than 1 Gbps.
        
    As a Solutions Architect, you have set up a database on a single EC2 instance that has an EBS volume of type gp2.
    You currently have 300GB of space on the gp2 device. The EC2 instance is of type m5.large. The database 
    performance has recently been poor and upon looking at CloudWatch, you realize the IOPS on the 
    EBS volume is maxing out. The disk size of the database must not change because of a licensing issue.
        Convert the gp2 volume to an io1
            io1 volume allows you to specify a consistent IOPS rate when you create the volume, 
            and Amazon EBS delivers the provisioned performance 99.9 percent of the time.
            IOPS cannot be directly increased on a gp2 volume without increasing its size, 
            which is not possible due to the question's constraints.
        
    The engineering team at an e-commerce company wants to set up a custom domain for internal 
    usage such as internaldomainexample.com. The team wants to use the private hosted zones feature 
    of Route 53 to accomplish this.Which of the following settings of the VPC need to be enabled? 
        enableDnsHostnames
        enableDnsSupport
            A private hosted zone is a container for records for a domain that you host in one or 
            more Amazon virtual private clouds (VPCs). You create a hosted zone for a domain (such as example.com), 
            and then you create records to tell Amazon Route 53 how you want traffic to be routed for 
            that domain within and among your VPCs.
            for each VPC that you want to associate with the Route 53 hosted zone, change the following 
            VPC settings to true:enableDnsHostnames,enableDnsSupport
    
    A development team has noticed that one of the EC2 instances has been incorrectly configured 
    with the 'DeleteOnTermination' attribute set to True for its root EBS volume.As a Solution's Architect, 
    can you suggest a way to disable this flag while the instance is still running?
        Set the DeleteOnTermination attribute to False using the command line
    
    A company maintains its business-critical customer data on an on-premises system in an encrypted format. 
    Over the years, the company has transitioned from using a single encryption key to multiple encryption keys 
    by dividing the data into logical chunks. With the decision to move all the data to an Amazon S3 bucket, 
    the company is now looking for a technique to encrypt each file with a different encryption key to provide 
    maximum security to the migrated on-premises data.How will you implement this requirement without adding 
    the overhead of splitting the data into logical groups?
        Configure a single Amazon S3 bucket to hold all data. 
        Use server-side encryption with Amazon S3 managed keys (SSE-S3) to encrypt the data
            When you use server-side encryption with Amazon S3 managed keys (SSE-S3), each object 
            is encrypted with a unique key. As an additional safeguard, it encrypts the key itself 
            with a root key that it regularly rotates.
    
    During a review, a security team has flagged concerns over an Amazon EC2 instance querying IP addresses 
    used for cryptocurrency mining. The EC2 instance does not host any authorized application related to 
    cryptocurrency mining.Which AWS service can be used to protect the EC2 instances from such 
    unauthorized behavior in the future?
        Amazon GuardDuty
            continuously monitors for malicious or unauthorized behavior to help protect your AWS resources, 
            including your AWS accounts and access keys. GuardDuty identifies any unusual or unauthorized activity, 
            like cryptocurrency mining or infrastructure deployments in a region that has never been used. 
            Powered by threat intelligence and machine learning, GuardDuty is continuously evolving to help 
            you protect your AWS environment.
    
    An engineering team wants to orchestrate multiple Amazon ECS task types running on EC2 instances 
    that are part of the ECS cluster. The output and state data for all tasks need to be stored. The amount 
    of data output by each task is approximately 20 MB and there could be hundreds of tasks running
    at a time. As old outputs are archived, the storage size is not expected to exceed 1 TB.As a solutions architect,
    which of the following would you recommend as an optimized solution for high-frequency reading and writing? 
        Use Amazon EFS with Provisioned Throughput mode
            Provisioned Throughput mode is available for applications with high throughput to storage 
            (MiB/s per TiB) ratios, or with requirements greater than those allowed by the Bursting Throughput mode.
            you can increase the Provisioned Throughput of your file system as often as you want. 
            You can decrease your file system throughput in Provisioned Throughput mode as long as 
            it's been more than 24 hours since the last decrease. Additionally, you can change between 
            Provisioned Throughput mode and the default Bursting Throughput mode as long as it’s been 
            more than 24 hours since the last throughput mode change.
            Bursting Throughput mode, a file system's throughput scales as the amount of data stored 
            in the standard storage class grows. File-based workloads are typically spiky, driving high 
            levels of throughput for short periods of time, and low levels of throughput the rest of the time. 
            To accommodate this, Amazon EFS is designed to burst to high throughput levels for periods of time. 
            By default, AWS recommends that you run your application in the Bursting Throughput mode. 
            But, if you're planning to migrate large amounts of data into your file system, 
            consider switching to Provisioned Throughput mode

    The engineering team at a retail company is planning to migrate to AWS Cloud from the on-premises 
    data center. The team is evaluating Amazon RDS as the database tier for its flagship application. 
    The team has hired you as an AWS Certified Solutions Architect Associate to advise on RDS Multi-AZ capabilities.
    Which of the following would you identify as correct for RDS Multi-AZ?
        Amazon RDS automatically initiates a failover to the standby, in case the primary database fails for any reason
        RDS applies OS updates by performing maintenance on the standby, then promoting the standby to primary, 
        and finally performing maintenance on the old primary, which becomes the new standby
    
    A Hollywood production studio is looking at transferring their existing digital media assets of around 
    20PB to AWS Cloud in the shortest possible timeframe.Which of the following is an optimal 
    solution for this requirement, given that the studio's data centers are located at a remote location?
        AWS Snowmobile
            can transfer up to 100PB per Snowmobile
            Transferring data with Snowmobile is more secure, fast, and cost-effective. 
            AWS recommends using Snowmobile to migrate large datasets of 10PB or more in a single location.
            For datasets less than 10PB or distributed in multiple locations, you should use Snowball.
    
    An application is hosted on multiple Amazon EC2 instances in the same Availability Zone. 
    The engineering team wants to set up shared data access for these EC2 instances using EBS Multi-Attach volumes.
    Which EBS volume type is the correct choice for these EC2 instances?
        Provisioned IOPS SSD EBS volumes
            Amazon EBS Multi-Attach enables you to attach a single Provisioned IOPS SSD (io1 or io2) volume
            to multiple instances that are in the same Availability Zone. You can attach multiple Multi-Attach
            enabled volumes to an instance or set of instances.
            Multi-Attach is supported exclusively on Provisioned IOPS SSD volumes.
        
    The engineering team at an IT company is deploying an Online Transactional Processing (OLTP) 
    application that needs to support relational queries. The application will have unpredictable 
    spikes of usage that the team does not know in advance.Which database would you recommend using?
        Aurora Serverless
    
    A company uses a legacy on-premises reporting application that operates on gigabytes of .json files 
    and represents years of data. The legacy application cannot handle the growing size of .json files. 
    New .json files are added daily from various data sources to a central on-premises storage location. 
    The company wants to continue to support the legacy application. The company has hired you as a 
    solutions architect to build a solution that can manage ongoing data updates from your on-premises 
    application to Amazon S3.
        Set up an on-premises file gateway. Configure data sources to write the .json files 
        to the file gateway. Point the legacy analytics application to the file gateway. 
        The file gateway should replicate the .json files to Amazon S3
            AWS DataSync to migrate existing data to Amazon S3, 
            File Gateway configuration of AWS Storage Gateway to retain access to the migrated 
            data and for ongoing updates from your on-premises file-based applications. 
        
    An e-commerce application uses a relational database that runs several queries that perform 
    joins on multiple tables. The development team has found that these queries are slow and expensive,
    therefore these are a good candidate for caching. The application needs to use a caching service 
    that supports multi-threading.
        Amazon ElastiCache for Memcached 
            Choose Memcached if 
                You need the simplest model possible.
                You need to run large nodes with multiple cores or threads (support for multi-threading).
                You need the ability to scale out and in, adding and removing nodes as 
                demand on your system increases and decreases.
                You need to cache objects.
            Redis does not support multi-threading
    
    























    
    














